<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">

  <head>
  
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Deep learning &middot; Yu's Tech 블로그
    
  </title>

  <!-- BOOTSTRAP -->
  <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>

  <!-- CODE BLOCK FONT -->
  <link href="http://cdn.jsdelivr.net/gh/joungkyun/font-d2coding/d2coding.css" rel="stylesheet" type="text/css">

  <!-- SCROLLSPY-->
  <script src="https://unpkg.com/scrollnav@3.0.2/dist/scrollnav.min.umd.js"></script>
  <link rel="stylesheet" href="/assets/css/style.css">

  
  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/lanyon.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700|PT+Sans:400">

    <!-- syntax.css -->
  <link rel="stylesheet" href="/assets/css/syntax.css">

  <!-- font -->
  <link rel="preconnect" href="https://fonts.gstatic.com">
  <link href="https://fonts.googleapis.com/css2?family=Nanum+Gothic&display=swap" rel="stylesheet">
  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-144-precomposed.png">
  <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">

  <!-- Google Analytics -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-146052-15', 'getpoole.com');
    ga('send', 'pageview');
  </script>

</head>

  <!--
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
-->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
    }
  });
</script>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>



  <body>

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <p>You will never know until you try.</p>
  </div>

  <nav class="sidebar-nav">
    <a class="sidebar-nav-item" href="/">Home <small class="text-info">23</small></a>

    

    <!-- 
    
      
        
      
    
      
        
          <a class="sidebar-nav-item" href="/about/">About</a>
        
      
    
      
    
      
    
      
    
      
        
          <a class="sidebar-nav-item" href="/category/Algorithm/index.html">Algorithm</a>
        
      
    
      
        
          <a class="sidebar-nav-item active" href="/category/Deep%20learning/index.html">Deep learning</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="/category/Docker/index.html">Docker</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="/category/HPC/index.html">HPC</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="/category/Lecture/index.html">Lecture</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="/category/Mongodb/index.html">Mongodb</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="/category/OpenCL/index.html">OpenCL</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="/category/Operating%20system/index.html">Operating system</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="/category/Python/index.html">Python</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="/category/Spark/index.html">Spark</a>
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
    
 -->
    
      <a class = "sidebar-nav-item " href="/category/Python/index.html">Python <small class="text-info">3</small></a>  
    <!--<a class="sidebar-nav-item" href="/category/Python/index.html">Python</a>  <small class="text-muted">3</small>-->
    
      <a class = "sidebar-nav-item " href="/category/Mongodb/index.html">Mongodb <small class="text-info">1</small></a>  
    <!--<a class="sidebar-nav-item" href="/category/Mongodb/index.html">Mongodb</a>  <small class="text-muted">1</small>-->
    
      <a class = "sidebar-nav-item " href="/category/Spark/index.html">Spark <small class="text-info">1</small></a>  
    <!--<a class="sidebar-nav-item" href="/category/Spark/index.html">Spark</a>  <small class="text-muted">1</small>-->
    
      <a class = "sidebar-nav-item " href="/category/Algorithm/index.html">Algorithm <small class="text-info">4</small></a>  
    <!--<a class="sidebar-nav-item" href="/category/Algorithm/index.html">Algorithm</a>  <small class="text-muted">4</small>-->
    
      <a class = "sidebar-nav-item  active" href="/category/Deep learning/index.html">Deep learning <small class="text-info">1</small></a>  
    <!--<a class="sidebar-nav-item" href="/category/Deep learning/index.html">Deep learning</a>  <small class="text-muted">1</small>-->
    
      <a class = "sidebar-nav-item " href="/category/OpenCL/index.html">OpenCL <small class="text-info">1</small></a>  
    <!--<a class="sidebar-nav-item" href="/category/OpenCL/index.html">OpenCL</a>  <small class="text-muted">1</small>-->
    
      <a class = "sidebar-nav-item " href="/category/Operating system/index.html">Operating system <small class="text-info">1</small></a>  
    <!--<a class="sidebar-nav-item" href="/category/Operating system/index.html">Operating system</a>  <small class="text-muted">1</small>-->
    
      <a class = "sidebar-nav-item " href="/category/Lecture/index.html">Lecture <small class="text-info">8</small></a>  
    <!--<a class="sidebar-nav-item" href="/category/Lecture/index.html">Lecture</a>  <small class="text-muted">8</small>-->
    
      <a class = "sidebar-nav-item " href="/category/HPC/index.html">HPC <small class="text-info">1</small></a>  
    <!--<a class="sidebar-nav-item" href="/category/HPC/index.html">HPC</a>  <small class="text-muted">1</small>-->
    
      <a class = "sidebar-nav-item " href="/category/Docker/index.html">Docker <small class="text-info">2</small></a>  
    <!--<a class="sidebar-nav-item" href="/category/Docker/index.html">Docker</a>  <small class="text-muted">2</small>-->
    
    
<!--
    <a class="sidebar-nav-item" href="https://github.com/Yujaeseo/Yujaeseo.github.io.git/archive/v1.0.0.zip">Download</a>
    <a class="sidebar-nav-item" href="https://github.com/Yujaeseo/Yujaeseo.github.io.git">GitHub project</a>
    <span class="sidebar-nav-item">Currently v1.0.0</span>
-->
  </nav>
<!--
  <div class="sidebar-item">
    <p>
      &copy; 2022. All rights reserved.
    </p>
  </div>
-->
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap">
      <div class="masthead">
        <div class="container">
          <h3 class="masthead-title">
            <a href="/" title="Home">Yu's Tech 블로그</a>
            <small>프로그래밍 이야기</small>
          </h3>
        </div>
      </div>

      <div class="container content">
        <div class="posts">
    
    
      <div class="index-post">
            <h1 class="post-title">
            <a href="/deep%20learning/2021/08/13/About-CNN/">
                CNN (Convolutional Neural Networks)에 대한 기본적인 내용 정리
            </a>
            </h1>

            <span class="post-date">13 Aug 2021</span>
            
            
              
                <span class="badge badge-dark">Deep learning</span>
              
            
              
                <span class="badge badge-dark">Convolutional Neural Networks</span>
              
            
            
            <!-- <hr />

<h2 id="cnn-convolutional-neural-networks-이란"><strong>CNN (Convolutional Neural Networks) 이란?</strong></h2>

<p>CNN 모델은 convolution 연산을 활용하는 neural networks의 한 종류이다. 즉, neural network 모델 내 적어도 최소 한 개의 layer에서 convolution 연산이 사용될 경우 이를 CNN 모델이라고 할 수 있다. CNN은 보통 이미지 내의 특정 물체 또는 특징들을 발견하고 이해하는 컴퓨터비전 분야의 여러 task (Image detection, classification 등)에서 주로 사용된다.</p>

<h3 id="convolution-operation"><strong>Convolution operation</strong></h3>

<p>Convolution 연산은 사각형 모양의 2차원 filter를 input matrix 위로 sliding하며 수행된다. Figure 1에서와 같이 filter가 input의 왼쪽에서 오른쪽으로 이동하며 오른쪽 끝에 도달하면 그 다음 행의 왼쪽 부터 다시 sliding을 시작한다. 이때 특정 위치마다 filter를 적용하게 되는데, filter와 input의 각 pixel에 대응되는 값끼리 곱한 후 이를 합하여 단일 output을 산출하게 한다. 그러면 이러한 convolution 연산은 왜 사용하게 되는 것일까.</p>

<p><br />
<img src="https://miro.medium.com/max/875/1*VVvdh-BUKFh2pwDD0kPeRA@2x.gif" alt="image" width="70%" height="70%" class="align-center" />
<em>Figure 1. Convolution operation (<a href="https://towardsdatascience.com/applied-deep-learning-part-4-convolutional-neural-networks-584bc134c1e2">source</a>)</em>
<br /></p>

<p>Convolution을 사용하는 이유는 컴퓨터가 이미지 내에 존재하는 특정 물체에 대한 특징을 효과적으로 추출하기 위해서이다. 이미지 분류 task를 예로 들면, 만약 컴퓨터가 특정 이미지가 사람의 이미지 인지를 분류하기 위해서는 사람이 나온 이미지들의 특성을 파악하고, input으로 주어지는 이미지에 해당 특성이 나타나는 지를 판단해야 한다. 사람이 사람 이미지 특성을 직접 컴퓨터에 입력할 수 있지만, 사람들 간의 다양성을 모두 반영한 특성을 파악하기란 쉽지 않다. 하지만, 우리는 딥러닝 모델이 데이터를 통해 컴퓨터가 직접 사람의 특성을 학습하고 이를 통해 분류를 자동으로 하도록 할 수 있다.</p>

<p>그렇다면, fully connected layer를 통해 이미지 내의 특징을 추출할 수 는 없을까. 결과적으로 convolution 연산이 컴퓨터비전 분야에 더 적합하다. 그 이유는 convolution 연산이 2차원 input에서 feature를 더 잘 찾기 때문이다. Convolution 연산은 데이터의 형상을 보존하기 때문에, 이미지 데이터의 공간적인 정보를 반영하여 정보를 추출할 수 있다. Fully connected layer의 경우는 2차원 이미지가 주어질 때, 이를 1차원으로 flatten 하여 연산을 수행하기 때문에 데이터의 변환 과정에서 이미지 내의 공간적인 정보가 사라지게 된다.</p>

<p>즉, 이미지의 특정 픽셀은 주변 픽셀과의 관계를 통해서 의미를 갖게 되기 때문에 feature 추출 시 이미지의 공간적인 정보를 보존하고 반영하는 것이 무엇보다 중요한 것이다. 하지만 fully connected layer는 특정 output을 산출하기 위해서 input의 모든 pixel을 반영하게 되는데, 이는 불필요한 정보까지 사용하여 학습을 하게 된다. 반면, convolution 연산 시 특정 neuron에게 전달되는 값은 모든 pixel이 아닌 특정 공간 내에 있는 pixel들로, feature 추출에 의미있는 pixel 값만을 사용하여 학습하게 된다.</p>

<p>이와 같은 convolution operation을 수행하는 특정 layer를 convolution layer라고 하며, 다수의 convolution layer가 층층이 쌓여서 CNN 모델을 구성하게 된다. 이때 각 layer내에는 추출하고자 하는 feature 수에 따라 여러 개의 filter를 둘 수 있다. 각 convolution layer의 input을 input featrue map, output을 output feature map이라고 부른다.</p>

<p><br />
<img src="/assets/img/cnn%20spatial%20structure.png" alt="image" width="70%" height="70%" class="align-center" />
<em>Figure 2. Feature extraction with convolution (<a href="http://introtodeeplearning.com/slides/6S191_MIT_DeepLearning_L3.pdf">source</a>)</em>
<br /></p>

<h3 id="strides"><strong>Strides</strong></h3>

<p>Strides는 convolution filter를 적용하는 위치 간격을 말한다. 만약 strides 설정 값이 2이면 필터를 각 차원(가로, 세로)에 대해서 두칸씩 움직이게 된다. Strides 간격이 1보다 클 경우는 filter가 이미지를 더 큰 간격으로 sliding하며 feature를 추출하기 때문에 subsample을 수행하는 것과 같은 역할을 한다. stides 크기는 보통 5, 3, 2, 1로 설정한다.</p>

<p><br />
<img src="https://miro.medium.com/max/695/1*nGHLq1hx0gt02OK4l8WmRg.png" alt="image" width="70%" height="70%" class="align-center" />
<em>Figure 3. Convolution with strides of 2 (<a href="https://medium.com/@RaghavPrabhu/understanding-of-convolutional-neural-network-cnn-deep-learning-99760835f148">source</a>)</em>
<br /></p>

<h3 id="padding"><strong>Padding</strong></h3>

<p>Padding은 입력 데이터 주변에 특정 값을 채우는 과정을 말한다. 데이터 주변에 추가적인 행/열을 추가하게 되며 보통 해당 위치에 0을 넣는다. Padding 적용 시 얻는 효과는 크게 세 가지가 있다. 첫번째는 output 차원이 급격히 줄어드는 것을 방지할 수 있다는 점이다. 두번째는 필터 학습 시 학습이 적게 될 수 있는 이미지 테두리 부분에서의 정보 손실을 줄일 수 있다는 점이다. 세번째는 strides 간격을 1보다 크게 설정할 경우, filter가 image 범위를 벗어나는 경우가 생기게 되는데, padding을 넣을 경우 이를 막아줄 수 있다는 것이다. Padding을 적용하지 않을 경우 이를 valid padding이라고 하며, 이때 filter는 input feature map 내에서만 sliding을 하게 된다. feature map 내에서만 sliding을 해야하기 때문에 input feature map의 오른쪽과 밑에 손실되는 정보가 발생하게 되며, strides의 크기에 따라 손실되는 정보의 양이 달라지게 된다. 반면, input과 output의 크기가 동일하도록 padding을 설정할 때 이를 same padding이라고 부른다.</p>

<p><br />
<img src="https://miro.medium.com/max/741/1*1okwhewf5KCtIPaFib4XaA.gif" alt="image" width="60%" height="60%" class="align-center" />
<em>Figure 4. Padding example (<a href="https://towardsdatascience.com/types-of-convolutions-in-deep-learning-717013397f4d">source</a>)</em>
<br /></p>

<h3 id="그외-중요한-convolution-관련-연산"><strong>그외 중요한 convolution 관련 연산</strong></h3>

<h4 id="pooling"><strong>Pooling</strong></h4>

<p>Pooling은 input에서 subsampling을 수행하는 방법으로, input의 특정 영역에 있는 값들을 해당 영역의 statistics로 대체하게 된다. Average, max, min 등 여러 방법이 있으며, 최대 값을 취하는 max pooling이 일반적으로 많이 사용된다. Pooling을 사용하게 되면 input의 크기가 줄어들게 되며, 메모리 등 컴퓨터 자원을 아낄 수 있게 된다. 또한 pooling은 CNN 모델이 translation invariance한 성격을 갖도록 한다. 즉 만약 어떤 물체를 분류할 때, 물체의 위치가 어느 정도 변하여도 동일한 output을 내게 된다. translation invariance는 이미지에서 특정 feature가 존재하는 지 여부를 아는 것이 중요한 task일 때, 즉 물체의 위치를 아는 것이 중요하지 않을 때 필요한 중요한 성질이다.</p>

<p><br />
<img src="/assets/img/pooling.png" alt="image" width="70%" height="70%" class="align-center" />
<em>Figure 5. Pooling with 2x2 (<a href="https://fullstackdeeplearning.com/spring2021/lecture-2a/">source</a>)</em>
<br /></p>

<h4 id="dilated-convolution"><strong>Dilated convolution</strong></h4>

<p>Dilated convolution은 convolution filter 내 cell 간 간격(dilation)이 벌어진 convolution의 한 종류이다. Convolution filter 내 간격을 정의하는 dilation rate를 하이퍼파라미터로 두게 된다. 구현할 때에는 filter 내의 hole 부분은 0으로 채워 연산을 수행한다. Dialated convolution은 파라미터의 사이즈를 그대로 유지하면서 receptive field를 넓힐 수 있다. 이때, receptive field란 feature를 만들어 내는 input 영역을 말한다. receptive field가 작으면 좋지 않은데, 그 이유는 어떠한 판단을 하는 데 있어 중요한 정보가 고려되지 않을 수 있기 때문이다. 만약 특정 물체의 boundary를 판단하고 싶다고 할 때, receptive field가 물체보다 작다면 물체의 boundary를 명확히 판단할 수 없다.</p>

<p><br />
<img src="https://miro.medium.com/max/494/1*SVkgHoFoiMZkjy54zM_SUw.gif" alt="image" width="60%" height="60%" class="align-center" />
<em>Figure 6. 2D convolution using with a dilation rate of 2(<a href="https://towardsdatascience.com/types-of-convolutions-in-deep-learning-717013397f4d">source</a>)</em>
<br /></p>

<h4 id="1x1-convolution"><strong>1x1 convolution</strong></h4>

<p>1x1 convolution은 말 그대로 convolution filter의 차원이 1x1인 convolution을 말한다. 이는 보통 channel의 dimension을 줄이기 위해 사용된다. 1x1 convolution을 적용하게 되면 정보를 함축하여 표현하게 되고, 이에 따라 차원이 줄어 연산에 소요되는 시간이 줄어들게 된다.</p>

<p><br />
<img src="/assets/img/1x1%20convolution.png" alt="image" width="70%" height="70%" class="align-center" />
<em>Figure 7. 1x1 convolution example (<a href="https://fullstackdeeplearning.com/spring2021/lecture-2a/">source</a>)</em>
<br /></p>

<h2 id="classic-convnet-architecture"><strong>Classic convNet architecture</strong></h2>

<p>일반적인 CNN 모델은 convolution, non-linear, pooling 순서를 반복하는 feature learning 과정을 가지고 있다. 먼저 convolution 연산을 통해 image에서 feature를 뽑고, 그 다음 relu와 같은 activation funtion을 사용하여 데이터에 non-linearity를 부여한다. 마지막으로 pooling을 통해 차원을 줄이고 output이 translation invariance하게 한다. Feature learning 과정 다음에는 모델의 output을 내기 위한 과정이 존재한다. 이 과정은 task에 dependent한데, image classification의 경우 보통 몇 개의 fully connected layer를 두게 된다. Fully connected layer는 feature learning 과정에서 image에서 얻은 feature를 사용하여 classification을 수행하게 되고, 이미지가 특정 class에 속할 확률을 최종 ouput으로 만들어 낸다.</p>

<p><br />
<img src="/assets/img/General%20architecture%20cnn.png" alt="image" width="80%" height="70%" class="align-center" />
<em>Figure 8. Standard CNN model architecture (<a href="https://fullstackdeeplearning.com/spring2021/lecture-2a/">source</a>)</em>
<br /></p>

<h2 id="reference"><strong>Reference</strong></h2>

<ol>
  <li>https://fullstackdeeplearning.com/spring2021/lecture-2a/</li>
  <li>https://www.youtube.com/watch?v=AjtX1N_VT9E&amp;list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI&amp;index=4</li>
  <li>https://theaisummer.com/receptive-field/</li>
</ol>

 -->
            <div class="text-muted post-excerpt">일반적인 CNN 모델의 구조와 convolution 연산을 비롯하여 CNN 모델을 구성하는 요소에 대해 알아본다.</div>
        </div>
        <!-- <div class="post">
          <h1 class="post-title">
          <a href="/deep%20learning/2021/08/13/About-CNN/">
              CNN (Convolutional Neural Networks)에 대한 기본적인 내용 정리
          </a>
          </h1>

          <span class="post-date">13 Aug 2021</span>
          
          
            
              <span class="badge badge-dark">Deep learning</span>
            
          
            
              <span class="badge badge-dark">Convolutional Neural Networks</span>
            
          
          
          <hr />

<h2 id="cnn-convolutional-neural-networks-이란"><strong>CNN (Convolutional Neural Networks) 이란?</strong></h2>

<p>CNN 모델은 convolution 연산을 활용하는 neural networks의 한 종류이다. 즉, neural network 모델 내 적어도 최소 한 개의 layer에서 convolution 연산이 사용될 경우 이를 CNN 모델이라고 할 수 있다. CNN은 보통 이미지 내의 특정 물체 또는 특징들을 발견하고 이해하는 컴퓨터비전 분야의 여러 task (Image detection, classification 등)에서 주로 사용된다.</p>

<h3 id="convolution-operation"><strong>Convolution operation</strong></h3>

<p>Convolution 연산은 사각형 모양의 2차원 filter를 input matrix 위로 sliding하며 수행된다. Figure 1에서와 같이 filter가 input의 왼쪽에서 오른쪽으로 이동하며 오른쪽 끝에 도달하면 그 다음 행의 왼쪽 부터 다시 sliding을 시작한다. 이때 특정 위치마다 filter를 적용하게 되는데, filter와 input의 각 pixel에 대응되는 값끼리 곱한 후 이를 합하여 단일 output을 산출하게 한다. 그러면 이러한 convolution 연산은 왜 사용하게 되는 것일까.</p>

<p><br />
<img src="https://miro.medium.com/max/875/1*VVvdh-BUKFh2pwDD0kPeRA@2x.gif" alt="image" width="70%" height="70%" class="align-center" />
<em>Figure 1. Convolution operation (<a href="https://towardsdatascience.com/applied-deep-learning-part-4-convolutional-neural-networks-584bc134c1e2">source</a>)</em>
<br /></p>

<p>Convolution을 사용하는 이유는 컴퓨터가 이미지 내에 존재하는 특정 물체에 대한 특징을 효과적으로 추출하기 위해서이다. 이미지 분류 task를 예로 들면, 만약 컴퓨터가 특정 이미지가 사람의 이미지 인지를 분류하기 위해서는 사람이 나온 이미지들의 특성을 파악하고, input으로 주어지는 이미지에 해당 특성이 나타나는 지를 판단해야 한다. 사람이 사람 이미지 특성을 직접 컴퓨터에 입력할 수 있지만, 사람들 간의 다양성을 모두 반영한 특성을 파악하기란 쉽지 않다. 하지만, 우리는 딥러닝 모델이 데이터를 통해 컴퓨터가 직접 사람의 특성을 학습하고 이를 통해 분류를 자동으로 하도록 할 수 있다.</p>

<p>그렇다면, fully connected layer를 통해 이미지 내의 특징을 추출할 수 는 없을까. 결과적으로 convolution 연산이 컴퓨터비전 분야에 더 적합하다. 그 이유는 convolution 연산이 2차원 input에서 feature를 더 잘 찾기 때문이다. Convolution 연산은 데이터의 형상을 보존하기 때문에, 이미지 데이터의 공간적인 정보를 반영하여 정보를 추출할 수 있다. Fully connected layer의 경우는 2차원 이미지가 주어질 때, 이를 1차원으로 flatten 하여 연산을 수행하기 때문에 데이터의 변환 과정에서 이미지 내의 공간적인 정보가 사라지게 된다.</p>

<p>즉, 이미지의 특정 픽셀은 주변 픽셀과의 관계를 통해서 의미를 갖게 되기 때문에 feature 추출 시 이미지의 공간적인 정보를 보존하고 반영하는 것이 무엇보다 중요한 것이다. 하지만 fully connected layer는 특정 output을 산출하기 위해서 input의 모든 pixel을 반영하게 되는데, 이는 불필요한 정보까지 사용하여 학습을 하게 된다. 반면, convolution 연산 시 특정 neuron에게 전달되는 값은 모든 pixel이 아닌 특정 공간 내에 있는 pixel들로, feature 추출에 의미있는 pixel 값만을 사용하여 학습하게 된다.</p>

<p>이와 같은 convolution operation을 수행하는 특정 layer를 convolution layer라고 하며, 다수의 convolution layer가 층층이 쌓여서 CNN 모델을 구성하게 된다. 이때 각 layer내에는 추출하고자 하는 feature 수에 따라 여러 개의 filter를 둘 수 있다. 각 convolution layer의 input을 input featrue map, output을 output feature map이라고 부른다.</p>

<p><br />
<img src="/assets/img/cnn%20spatial%20structure.png" alt="image" width="70%" height="70%" class="align-center" />
<em>Figure 2. Feature extraction with convolution (<a href="http://introtodeeplearning.com/slides/6S191_MIT_DeepLearning_L3.pdf">source</a>)</em>
<br /></p>

<h3 id="strides"><strong>Strides</strong></h3>

<p>Strides는 convolution filter를 적용하는 위치 간격을 말한다. 만약 strides 설정 값이 2이면 필터를 각 차원(가로, 세로)에 대해서 두칸씩 움직이게 된다. Strides 간격이 1보다 클 경우는 filter가 이미지를 더 큰 간격으로 sliding하며 feature를 추출하기 때문에 subsample을 수행하는 것과 같은 역할을 한다. stides 크기는 보통 5, 3, 2, 1로 설정한다.</p>

<p><br />
<img src="https://miro.medium.com/max/695/1*nGHLq1hx0gt02OK4l8WmRg.png" alt="image" width="70%" height="70%" class="align-center" />
<em>Figure 3. Convolution with strides of 2 (<a href="https://medium.com/@RaghavPrabhu/understanding-of-convolutional-neural-network-cnn-deep-learning-99760835f148">source</a>)</em>
<br /></p>

<h3 id="padding"><strong>Padding</strong></h3>

<p>Padding은 입력 데이터 주변에 특정 값을 채우는 과정을 말한다. 데이터 주변에 추가적인 행/열을 추가하게 되며 보통 해당 위치에 0을 넣는다. Padding 적용 시 얻는 효과는 크게 세 가지가 있다. 첫번째는 output 차원이 급격히 줄어드는 것을 방지할 수 있다는 점이다. 두번째는 필터 학습 시 학습이 적게 될 수 있는 이미지 테두리 부분에서의 정보 손실을 줄일 수 있다는 점이다. 세번째는 strides 간격을 1보다 크게 설정할 경우, filter가 image 범위를 벗어나는 경우가 생기게 되는데, padding을 넣을 경우 이를 막아줄 수 있다는 것이다. Padding을 적용하지 않을 경우 이를 valid padding이라고 하며, 이때 filter는 input feature map 내에서만 sliding을 하게 된다. feature map 내에서만 sliding을 해야하기 때문에 input feature map의 오른쪽과 밑에 손실되는 정보가 발생하게 되며, strides의 크기에 따라 손실되는 정보의 양이 달라지게 된다. 반면, input과 output의 크기가 동일하도록 padding을 설정할 때 이를 same padding이라고 부른다.</p>

<p><br />
<img src="https://miro.medium.com/max/741/1*1okwhewf5KCtIPaFib4XaA.gif" alt="image" width="60%" height="60%" class="align-center" />
<em>Figure 4. Padding example (<a href="https://towardsdatascience.com/types-of-convolutions-in-deep-learning-717013397f4d">source</a>)</em>
<br /></p>

<h3 id="그외-중요한-convolution-관련-연산"><strong>그외 중요한 convolution 관련 연산</strong></h3>

<h4 id="pooling"><strong>Pooling</strong></h4>

<p>Pooling은 input에서 subsampling을 수행하는 방법으로, input의 특정 영역에 있는 값들을 해당 영역의 statistics로 대체하게 된다. Average, max, min 등 여러 방법이 있으며, 최대 값을 취하는 max pooling이 일반적으로 많이 사용된다. Pooling을 사용하게 되면 input의 크기가 줄어들게 되며, 메모리 등 컴퓨터 자원을 아낄 수 있게 된다. 또한 pooling은 CNN 모델이 translation invariance한 성격을 갖도록 한다. 즉 만약 어떤 물체를 분류할 때, 물체의 위치가 어느 정도 변하여도 동일한 output을 내게 된다. translation invariance는 이미지에서 특정 feature가 존재하는 지 여부를 아는 것이 중요한 task일 때, 즉 물체의 위치를 아는 것이 중요하지 않을 때 필요한 중요한 성질이다.</p>

<p><br />
<img src="/assets/img/pooling.png" alt="image" width="70%" height="70%" class="align-center" />
<em>Figure 5. Pooling with 2x2 (<a href="https://fullstackdeeplearning.com/spring2021/lecture-2a/">source</a>)</em>
<br /></p>

<h4 id="dilated-convolution"><strong>Dilated convolution</strong></h4>

<p>Dilated convolution은 convolution filter 내 cell 간 간격(dilation)이 벌어진 convolution의 한 종류이다. Convolution filter 내 간격을 정의하는 dilation rate를 하이퍼파라미터로 두게 된다. 구현할 때에는 filter 내의 hole 부분은 0으로 채워 연산을 수행한다. Dialated convolution은 파라미터의 사이즈를 그대로 유지하면서 receptive field를 넓힐 수 있다. 이때, receptive field란 feature를 만들어 내는 input 영역을 말한다. receptive field가 작으면 좋지 않은데, 그 이유는 어떠한 판단을 하는 데 있어 중요한 정보가 고려되지 않을 수 있기 때문이다. 만약 특정 물체의 boundary를 판단하고 싶다고 할 때, receptive field가 물체보다 작다면 물체의 boundary를 명확히 판단할 수 없다.</p>

<p><br />
<img src="https://miro.medium.com/max/494/1*SVkgHoFoiMZkjy54zM_SUw.gif" alt="image" width="60%" height="60%" class="align-center" />
<em>Figure 6. 2D convolution using with a dilation rate of 2(<a href="https://towardsdatascience.com/types-of-convolutions-in-deep-learning-717013397f4d">source</a>)</em>
<br /></p>

<h4 id="1x1-convolution"><strong>1x1 convolution</strong></h4>

<p>1x1 convolution은 말 그대로 convolution filter의 차원이 1x1인 convolution을 말한다. 이는 보통 channel의 dimension을 줄이기 위해 사용된다. 1x1 convolution을 적용하게 되면 정보를 함축하여 표현하게 되고, 이에 따라 차원이 줄어 연산에 소요되는 시간이 줄어들게 된다.</p>

<p><br />
<img src="/assets/img/1x1%20convolution.png" alt="image" width="70%" height="70%" class="align-center" />
<em>Figure 7. 1x1 convolution example (<a href="https://fullstackdeeplearning.com/spring2021/lecture-2a/">source</a>)</em>
<br /></p>

<h2 id="classic-convnet-architecture"><strong>Classic convNet architecture</strong></h2>

<p>일반적인 CNN 모델은 convolution, non-linear, pooling 순서를 반복하는 feature learning 과정을 가지고 있다. 먼저 convolution 연산을 통해 image에서 feature를 뽑고, 그 다음 relu와 같은 activation funtion을 사용하여 데이터에 non-linearity를 부여한다. 마지막으로 pooling을 통해 차원을 줄이고 output이 translation invariance하게 한다. Feature learning 과정 다음에는 모델의 output을 내기 위한 과정이 존재한다. 이 과정은 task에 dependent한데, image classification의 경우 보통 몇 개의 fully connected layer를 두게 된다. Fully connected layer는 feature learning 과정에서 image에서 얻은 feature를 사용하여 classification을 수행하게 되고, 이미지가 특정 class에 속할 확률을 최종 ouput으로 만들어 낸다.</p>

<p><br />
<img src="/assets/img/General%20architecture%20cnn.png" alt="image" width="80%" height="70%" class="align-center" />
<em>Figure 8. Standard CNN model architecture (<a href="https://fullstackdeeplearning.com/spring2021/lecture-2a/">source</a>)</em>
<br /></p>

<h2 id="reference"><strong>Reference</strong></h2>

<ol>
  <li>https://fullstackdeeplearning.com/spring2021/lecture-2a/</li>
  <li>https://www.youtube.com/watch?v=AjtX1N_VT9E&amp;list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI&amp;index=4</li>
  <li>https://theaisummer.com/receptive-field/</li>
</ol>


      </div> -->
  

</div>
<div class="pagination">
    
      <span class="pagination-item newer">New</span>
    
  
    
      <span class="pagination-item older">Old</span>
    
  
  </div>


      </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

  </body>
  <script>
    const content = document.querySelector(".main-content");
    
    scrollnav.init(content,{
      debug: false,
      updateHistory: false,
      // easingStyle: 'easeOutQuint',
      sections: ($('.post-content > h1').length>0) ? 'h1' : 'h2',
      subSections: ($('.post-content > h1').length>0) ? 'h2' : 'h3'
    });
    
    var sideNav = function(){
      var mainRect = document.getElementById('main-content').getBoundingClientRect();
      $('nav.scroll-nav').css('left', mainRect.right + 50 + 'px');
    }
    
    sideNav();
    window.addEventListener("resize", sideNav);
    
   

    
    // window.addEventListener('load', (event) => {
    //   console.log('page is fully loaded');
    //   scrollnav.updatePositions();
  
    // });

  </script>
</html>

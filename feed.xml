<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2022-07-31T18:04:41+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Yu’s Tech 블로그</title><subtitle>You will never know until you try.</subtitle><author><name>Jaeseo Yu</name></author><entry><title type="html">Deploying Machine Learning Models in Production_Installing TensorFlow Serving</title><link href="http://localhost:4000/lecture/2022/07/31/Deploying-Machine-Learning-Models-in-Production-Installing-tensorflow-serving/" rel="alternate" type="text/html" title="Deploying Machine Learning Models in Production_Installing TensorFlow Serving" /><published>2022-07-31T00:00:00+09:00</published><updated>2022-07-31T00:00:00+09:00</updated><id>http://localhost:4000/lecture/2022/07/31/%5BDeploying%20Machine%20Learning%20Models%20in%20Production%5D%20Installing%20tensorflow%20serving</id><content type="html" xml:base="http://localhost:4000/lecture/2022/07/31/Deploying-Machine-Learning-Models-in-Production-Installing-tensorflow-serving/">&lt;hr /&gt;

&lt;h2 id=&quot;install-tensorflow-serving-1&quot;&gt;&lt;strong&gt;Install Tensorflow Serving (1)&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731110109225.png&quot; alt=&quot;image-20220731110109225&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Tensorflow serving을 설치하는 가장 쉬운 방법은 docker image를 사용하는 것이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;install-tensorflow-serving-2&quot;&gt;&lt;strong&gt;Install Tensorflow Serving (2)&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731110124591.png&quot; alt=&quot;image-20220731110124591&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Binaries를 이용해서 직접 다운로드 받는 방법은 다음과 같다.&lt;/li&gt;
  &lt;li&gt;Tensorflow-model-server는 플랫폼에 종속된 optimization 방식이 적용된 반면,&lt;/li&gt;
  &lt;li&gt;Tensorflow-model-server-universal은 플랫폼에 종속된 optimization 방식이 적용되지 않았다는 점이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;install-tensorflow-serving-3&quot;&gt;&lt;strong&gt;Install Tensorflow Serving (3)&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731110132863.png&quot; alt=&quot;image-20220731110132863&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;직접 customize를 하길 원한다면 source로도 build를 할 수 있다.&lt;/p&gt;

    &lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;install-tensorflow-serving-4&quot;&gt;&lt;strong&gt;Install Tensorflow Serving (4)&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731110141743.png&quot; alt=&quot;image-20220731110141743&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Tensorflow serving을 다운로드 받을 수 있는 archive 위치 정보를 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/etc/apt/sources.list.d&lt;/code&gt;에 등록한다.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;인증을 위한 key를 불러오고, apt 업데이트 후 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;apt-get&lt;/code&gt;을 이용하여 tensorflow serving을 다운받는다.&lt;/p&gt;

    &lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;import-the-mnist-dataset&quot;&gt;&lt;strong&gt;Import the MNIST Dataset&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731110150647.png&quot; alt=&quot;image-20220731110150647&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;MNIST 데이터셋을 이용하여 비전 모델을 학습시킨다.
    &lt;ul&gt;
      &lt;li&gt;70,000장 (train 60,000/ test 10,000)의 0-9 grayscale 이미지(28x28)로 이루어져있다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Numpy array 형식으로 데이터를 불러오고 0-1 scale 값으로 normalization을 수행한다.&lt;/p&gt;

    &lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;import-the-mnist-dataset-1&quot;&gt;&lt;strong&gt;Import the MNIST Dataset&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731110209791.png&quot; alt=&quot;image-20220731110209791&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Train, test 각각을 (60,000 x 28 x 28 x 1), (10,000 x 28 x 28 x 1) 형식의 array로 변환한다.&lt;/p&gt;

    &lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;look-at-a-sample-image&quot;&gt;&lt;strong&gt;Look at a Sample Image&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731110217800.png&quot; alt=&quot;image-20220731110217800&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Sample image를 확인한다.&lt;/p&gt;

    &lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;build-a-model&quot;&gt;&lt;strong&gt;Build a Model&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731110226735.png&quot; alt=&quot;image-20220731110226735&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;간단한 CNN 모델을 구성한다.&lt;/p&gt;

    &lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;train-the-model&quot;&gt;&lt;strong&gt;Train the Model&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731110234568.png&quot; alt=&quot;image-20220731110234568&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;모델 training에 사용할 optimizer, loss, metric을 세팅한다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Fit&lt;/code&gt;을 실행하면 모델 학습이 진행되고, history 변수에는 epoch by epoch accuracy가 저장된다.&lt;/p&gt;

    &lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;evaluate-the-model&quot;&gt;&lt;strong&gt;Evaluate the Model&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731110241758.png&quot; alt=&quot;image-20220731110241758&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Testset에 대해 학습된 모델의 정확도를 평가한다.
&lt;br /&gt;&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;save-the-model&quot;&gt;&lt;strong&gt;Save the Model&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731110250111.png&quot; alt=&quot;image-20220731110250111&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Tensorflow serving을 사용하기 위해서는 모델을 저장해야한다.&lt;/p&gt;

    &lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;launch-your-saved-model&quot;&gt;&lt;strong&gt;Launch Your Saved Model&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731110257655.png&quot; alt=&quot;image-20220731110257655&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;bash script로 tensorflow model server를 세팅해준다. (port, 모델 이름, 모델 path)&lt;/p&gt;

    &lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;send-an-inference-request&quot;&gt;&lt;strong&gt;Send an Inference Request&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731110306735.png&quot; alt=&quot;image-20220731110306735&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Test set에 속하는 몇개의 이미지를 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;json&lt;/code&gt; 형식으로 변환한후 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;POST&lt;/code&gt;로 서버에 request를 보낸다.&lt;/p&gt;

    &lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;plot-predictions&quot;&gt;&lt;strong&gt;Plot Predictions&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731110314567.png&quot; alt=&quot;image-20220731110314567&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;결과를 시각화하는 코드를 작성한다.&lt;/p&gt;

    &lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;results-demo&quot;&gt;&lt;strong&gt;Results Demo&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731110323919.png&quot; alt=&quot;image-20220731110323919&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;결과가 정확하게 나온 것을 확인할 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;</content><author><name>Jaeseo Yu</name></author><category term="Lecture" /><category term="mlops" /><category term="deep learning" /><category term="machine learning" /><category term="lecture summary" /><summary type="html">Google colab을 이용하여 tensorflow serving을 install하고 간단한 CNN 모델을 통해 실습을 진행한다.</summary></entry><entry><title type="html">Deploying Machine Learning Models in Production_Model Serving Architecture</title><link href="http://localhost:4000/lecture/2022/07/31/Deploying-Machine-Learning-Models-in-Production-Model-Serving-Architecture/" rel="alternate" type="text/html" title="Deploying Machine Learning Models in Production_Model Serving Architecture" /><published>2022-07-31T00:00:00+09:00</published><updated>2022-07-31T00:00:00+09:00</updated><id>http://localhost:4000/lecture/2022/07/31/%5BDeploying%20Machine%20Learning%20Models%20in%20Production%5D%20Model%20Serving%20Architecture</id><content type="html" xml:base="http://localhost:4000/lecture/2022/07/31/Deploying-Machine-Learning-Models-in-Production-Model-Serving-Architecture/">&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;ml-infrastructure-1&quot;&gt;&lt;strong&gt;ML Infrastructure (1)&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731165510452.png&quot; alt=&quot;image-20220731165510452&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Model serving을 위한 infrastructure에 대해 알아볼 것이다.&lt;/li&gt;
  &lt;li&gt;크게 자체 구축한 on-premise 환경 또는 cloud 서비스를 이용하는 두가지 방법이 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;ml-infrastructure_on-premise-2&quot;&gt;&lt;strong&gt;ML Infrastructure_On-Premise (2)&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731165518094.png&quot; alt=&quot;image-20220731165518094&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;On-Premise는 소유한 회사가 하드웨어와 소프트웨어에 대한 전적인 통제 권한을 가질 수 있다.&lt;/li&gt;
  &lt;li&gt;따라서, 시시각각 변하는 다양한 요구 조건에 빠르게 대처할 수 있다는 장점이 존재한다.&lt;/li&gt;
  &lt;li&gt;하지만 하드웨어 인프라를 직접 구하고, 설치하고, 유지보수해야한다는 점에서 큰 비용이 생긴다.&lt;/li&gt;
  &lt;li&gt;일반적으로 규모의 경제를 실현할 수 있는 큰 규모의 회사들이 on-premise 환경을 구축하고 운영한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;ml-infrastructure_cloud-3&quot;&gt;&lt;strong&gt;ML Infrastructure_Cloud (3)&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731165526447.png&quot; alt=&quot;image-20220731165526447&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;규모가 작은 기업들은 이러한 인프라를 전문 기업에게 outsourcing 하는 방법이 있다.&lt;/li&gt;
  &lt;li&gt;아마존, 구글, 마이크로소프트와 같은 기업들이 cloud 서비스를 제공한다.&lt;/li&gt;
  &lt;li&gt;하드웨어를 직접 구축할 필요가 없고 해당 기업들이 하드웨어, 소프트웨어 전반을 관리 및 모니터링해준다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;model-serving-1&quot;&gt;&lt;strong&gt;Model Serving (1)&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731165534694.png&quot; alt=&quot;image-20220731165534694&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;인프라 선택뿐만 아니라 model serving 방법 또한 선택해야한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;model-serving_on-premise-2&quot;&gt;&lt;strong&gt;Model Serving_On-Premise (2)&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731165542350.png&quot; alt=&quot;image-20220731165542350&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;On-premise에서는 원하는 model server를 선택하고 구축할 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;model-serving_cloud3&quot;&gt;&lt;strong&gt;Model Serving_Cloud(3)&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731165549647.png&quot; alt=&quot;image-20220731165549647&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Cloud를 사용하는 경우 cloud vendor에서 제공하는 tool과 service를 사용할 수 있다.
    &lt;ul&gt;
      &lt;li&gt;Google의 경우 automl을 비롯한 다양한 서비스를, amazon의 경우 sagemaker와 같은 서비스를 사용할 수 있다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;아니면 cloud에 VM을 활용하여 on-premise와 동일하게 직접 원하는 환경과 서비스를 구축할수도 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;model-servers-1&quot;&gt;&lt;strong&gt;Model Servers (1)&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731165556703.png&quot; alt=&quot;image-20220731165556703&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Model server의 역할을 간단하게 알아보자.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;model-servers_model-file2&quot;&gt;&lt;strong&gt;Model Servers_Model file(2)&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731165604454.png&quot; alt=&quot;image-20220731165604454&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;모델은 여러 버전으로 file system에 저장이 된다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;model-servers_model-server3&quot;&gt;&lt;strong&gt;Model Servers_Model server(3)&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731165612567.png&quot; alt=&quot;image-20220731165612567&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Model server는 model을 file에서 읽고 인스턴스로 생성하여, client에게 제공하길 원하는 task에 대한 response를 한다.&lt;/li&gt;
  &lt;li&gt;예를들어 Mobilenet을 이용한 classification을 수행한다고 했을 때, 모델 서버는 input으로 주어진 이미지를 tensor 형태로 변형하고 이를 model에 전달하여 inference 결과를 산출한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;model-servers_api4&quot;&gt;&lt;strong&gt;Model Servers_API(4)&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731165624486.png&quot; alt=&quot;image-20220731165624486&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Model server는 client에게 REST 또는 gRPC 형태의 API를 제공하고 inference 결과를 client에게 return한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;model-servers_popular-model-server5&quot;&gt;&lt;strong&gt;Model Servers_Popular model server(5)&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731165635639.png&quot; alt=&quot;image-20220731165635639&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;유명한 model server에는 Tensorflow serving, Torchserve, KF serving, Triton이 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;</content><author><name>Jaeseo Yu</name></author><category term="Lecture" /><category term="mlops" /><category term="deep learning" /><category term="machine learning" /><category term="lecture summary" /><summary type="html">Model serving에 필요한 infrastructure의 종류와 model server에 대해 알아본다.</summary></entry><entry><title type="html">Deploying Machine Learning Models in Production_Deployment Options</title><link href="http://localhost:4000/lecture/2022/07/30/Deploying-Machine-Learning-Models-in-Production-Deployment-Options/" rel="alternate" type="text/html" title="Deploying Machine Learning Models in Production_Deployment Options" /><published>2022-07-30T00:00:00+09:00</published><updated>2022-07-30T00:00:00+09:00</updated><id>http://localhost:4000/lecture/2022/07/30/%5BDeploying%20Machine%20Learning%20Models%20in%20Production%5D%20Deployment%20Options</id><content type="html" xml:base="http://localhost:4000/lecture/2022/07/30/Deploying-Machine-Learning-Models-in-Production-Deployment-Options/">&lt;hr /&gt;

&lt;h2 id=&quot;model-deployments&quot;&gt;&lt;strong&gt;Model Deployments&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220730095805422.png&quot; alt=&quot;image-20220730095805422&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;모델 배포는 데이터센터와 같이 대규모의 인프라 공간에 모델을 중앙집중형 서버에 배포하는 것과 각 사용자의 local device에 배포하는 두가지가 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;running-in-huge-data-centers&quot;&gt;&lt;strong&gt;Running in Huge Data Centers&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220730095619218.png&quot; alt=&quot;image-20220730095619218&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;데이터센터를 운영하면 cost를 줄이기 위한 노력을 수행한다.
    &lt;ul&gt;
      &lt;li&gt;Google과 같은 큰 기업들은 지속적으로 데이터센터의 resource utilization, application의 cost를 줄이려고 한다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;constrained-environment-mobile-phone&quot;&gt;&lt;strong&gt;Constrained Environment: Mobile Phone&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220730095627775.png&quot; alt=&quot;image-20220730095627775&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;거대한 데이터센터 뿐만 아니라 핸드폰과 같은 제한된 모바일 환경에서도 모델을 serving하기도 한다.&lt;/li&gt;
  &lt;li&gt;모바일핸드폰의 GPU에는 데이터센터에서 사용되는 GPU보다 크기가 훨씬 작고 메모리 용량은 일반적으로 4GB가 넘지 않는다.&lt;/li&gt;
  &lt;li&gt;이러한 GPU를 우리가 배포한 application이 점유하는 것이 아니라 실행되고 있는 여러 application이 점유하게 된다.&lt;/li&gt;
  &lt;li&gt;또한 GPU를 이용하여 연산을 가속화하면 배터리가 빨리 닳게 되고 열이 발생해 application에 대한 인식이 좋지 않아질 것이다.&lt;/li&gt;
  &lt;li&gt;마지막으로, application의 용량이 커지면 다운로드 받기 꺼려질 것이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;restrictions-in-a-constrained-environment&quot;&gt;&lt;strong&gt;Restrictions in a Constrained Environment&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220730095635328.png&quot; alt=&quot;image-20220730095635328&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;낮은 메모리 용량, 프로세싱 파워, 배터리 용량과 같은 제한된 요건을 갖기 때문에 edge device에 큰 모델을 배포할 수 없다.&lt;/li&gt;
  &lt;li&gt;이러한 이유로 보통 서버에 모델을 배포하고 REST API를 통해 서비스를 하지만, latency가 매우 중요할 때는  적합하지 않다.
    &lt;ul&gt;
      &lt;li&gt;자율주행자동차는 실시간으로 그때그때 판단을 해야 하는데, 서버와 통신을 하게 되면 network 지연과 같은 문제로 큰 문제가 초래될 수 있다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;prediction-latency-is-almost-always-important&quot;&gt;&lt;strong&gt;Prediction Latency is Almost Always Important&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220730095647690.png&quot; alt=&quot;image-20220730095647690&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;항상 latency 를 줄여 application의 response time을 줄여 user experience를 향상시켜라.
    &lt;ul&gt;
      &lt;li&gt;예외적인 경우는 prediction의 정확도가 훨씬 중요한 task를 수행할 때이다.&lt;/li&gt;
      &lt;li&gt;예시는 질병 분석이 있다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;이때 model complexity, size와 같은 trade-off 관계에 있는 요소들도 고려해야 하며, 발생하는 cost도 고려해야 한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;choose-best-model-for-the-task&quot;&gt;&lt;strong&gt;Choose Best Model for the Task&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220730095656008.png&quot; alt=&quot;image-20220730095656008&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;언급한 constraints를 기준으로 최적의 모델을 선택해야한다.
    &lt;ul&gt;
      &lt;li&gt;Mobilenet은 모바일 환경을 위해 개발된 모델이다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;other-strategies&quot;&gt;&lt;strong&gt;Other Strategies&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220730095702751.png&quot; alt=&quot;image-20220730095702751&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;프로파일링을 통해 병목지점을 파악하고,&lt;/li&gt;
  &lt;li&gt;특정 operation이 많은 시간을 차지한다는 것을 발견한다면, 해당 부분은 최적화해야 한다.&lt;/li&gt;
  &lt;li&gt;모델 자체를 최적화하여 더 빠르고 energy efficient한 모델을 만들수도 있며 특히 mobile 환경에서 중요하다.&lt;/li&gt;
  &lt;li&gt;사용하는 thread의 수를 늘리는 방법도 있다.
    &lt;ul&gt;
      &lt;li&gt;하지만 thread 수를 늘린다고 해서 무조건 성능이 좋아지는 것은 아니다.&lt;/li&gt;
      &lt;li&gt;무엇을 concurrent하게 실행하고 있는지 등에 따라 성능 차이가 발생한다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;web-applications-for-users&quot;&gt;&lt;strong&gt;Web Applications for Users&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220730095709919.png&quot; alt=&quot;image-20220730095709919&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;모델에서 서비스를 받는 유저는 request를 web application을 통해한다.&lt;/li&gt;
  &lt;li&gt;Model은 API 서비스 형태로 존재하고, 이러한 과정을 돕는 다양한 web framework들이 존재한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;serving-systems-for-easy-deployment&quot;&gt;&lt;strong&gt;Serving systems for easy deployment&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220730095716511.png&quot; alt=&quot;image-20220730095716511&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;모델 서빙 시스템은 다양한 방식으로 모델 배포를 관리한다.
    &lt;ul&gt;
      &lt;li&gt;서버에 모델을 배포하여 서비스를 제공할 수 있으며,&lt;/li&gt;
      &lt;li&gt;Custom website가 필요하지 않고,&lt;/li&gt;
      &lt;li&gt;몇줄 안되는 코드로 배포가 가능하고,&lt;/li&gt;
      &lt;li&gt;Model update와 rollback을 편리하게 수행할 수 있다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;clipper&quot;&gt;&lt;strong&gt;Clipper&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220730095723575.png&quot; alt=&quot;image-20220730095723575&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Clipper는 UC berkely에서 만든 model serving 시스템이다.
    &lt;ul&gt;
      &lt;li&gt;다양한 모델 배포를 지원하며, restful API로 기존 application과 쉽게 통합할 수 있으며, 도커로 컨테이너화하여 자원 관리를 지원하며, latency setting을 할 수 있다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;tensorflow-serving&quot;&gt;&lt;strong&gt;TensorFlow Serving&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220730095732320.png&quot; alt=&quot;image-20220730095732320&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Tensorflow serving은 구글에서 만든 오픈소스이다.
    &lt;ul&gt;
      &lt;li&gt;텐서플로우 모델을 쉽게 배포할 수 있으며,&lt;/li&gt;
      &lt;li&gt;다른 타입의 모델도 배포할 수 있으며,&lt;/li&gt;
      &lt;li&gt;REST와 gRPC 프로토콜을 제공하며,&lt;/li&gt;
      &lt;li&gt;모델의 version management가 가능하다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;advantages-of-serving-with-a-managed-service&quot;&gt;&lt;strong&gt;Advantages of Serving with a Managed Service&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220730095739374.png&quot; alt=&quot;image-20220730095739374&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Google cloud와 같은 managed service를 사용하면 더 편할 수 있다.
    &lt;ul&gt;
      &lt;li&gt;낮은 latency의 endpoint를 제공하고 대량의 batch를 처리할 수 있으며,&lt;/li&gt;
      &lt;li&gt;별도 환경 또는 클라우드에서 학습한 모델을 배포할 수 있으며,&lt;/li&gt;
      &lt;li&gt;traffic에 기반하여 자동으로 scaling을 수행하고&lt;/li&gt;
      &lt;li&gt;GPU/TPU와 같은 연산 가속기도 지원한다.
        &lt;ul&gt;
          &lt;li&gt;Google 외에도 MS, Amazon과 같은 기업들이 비슷한 서비스를 제공한다.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;</content><author><name>Jaeseo Yu</name></author><category term="Lecture" /><category term="mlops" /><category term="deep learning" /><category term="machine learning" /><category term="lecture summary" /><summary type="html">Model serving을 위한 다양한 option들에 대해 알아본다.</summary></entry><entry><title type="html">Deploying Machine Learning Models in Production_Introduction to Model Serving Infrastructure</title><link href="http://localhost:4000/lecture/2022/07/29/Deploying-Machine-Learning-Models-in-Production-Introduction-to-Model-Serving-Infrastructure/" rel="alternate" type="text/html" title="Deploying Machine Learning Models in Production_Introduction to Model Serving Infrastructure" /><published>2022-07-29T00:00:00+09:00</published><updated>2022-07-29T00:00:00+09:00</updated><id>http://localhost:4000/lecture/2022/07/29/%5BDeploying%20Machine%20Learning%20Models%20in%20Production%5D%20Introduction%20to%20Model%20Serving%20Infrastructure</id><content type="html" xml:base="http://localhost:4000/lecture/2022/07/29/Deploying-Machine-Learning-Models-in-Production-Introduction-to-Model-Serving-Infrastructure/">&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;optimizing-models-for-serving&quot;&gt;&lt;strong&gt;Optimizing Models for Serving&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220729225850339.png&quot; alt=&quot;image-20220729225850339&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;최근 모델의 정확도를 높이기 위해 model에 feature 수를 늘리는 등 모델 자체의 complexity가 커지고 있다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;정확도는 높아지지만 이로인해 prediction latency도 커지고 있다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;as-model-complexity-increases-cost-increases&quot;&gt;&lt;strong&gt;As Model Complexity Increases Cost Increases&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220729225858482.png&quot; alt=&quot;image-20220729225858482&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;모델 complexity의 증가는 비용을 초래한다.&lt;/li&gt;
  &lt;li&gt;GPU, TPU와 같은 하드웨어와 model registry, maintenance에 있어서의 비용이 포함된다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;balancing-cost-and-complexity&quot;&gt;&lt;strong&gt;Balancing Cost and Complexity&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220729225907449.png&quot; alt=&quot;image-20220729225907449&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;모델의 정확도와 prediction 속도 간에는 trade-off 관계가 존재하며, 이 사이의 균형을 맞추는 것이 중요하다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;optimizing-and-satisficing-metrics&quot;&gt;&lt;strong&gt;Optimizing and Satisficing Metrics&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220729225915162.png&quot; alt=&quot;image-20220729225915162&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;모델의 정확도를 측정하는 metric으로 accuracy, precision, recall이 있다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;반면, 연산상의 제약 조건과 관련된 metric으로는 latency, model size, GPU load가 있다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;optimizing-and-satisficing-metrics-1&quot;&gt;&lt;strong&gt;Optimizing and Satisficing Metrics&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220729225927745.png&quot; alt=&quot;image-20220729225927745&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;이와 같은 metric을 만족하는 방법은 우선 특정한 serving infrastructure에서 model의 complexity를 증가시키는 것이다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Latency와 같은 연산 상의 제약조건 metric threshold에(e.g. latency) 걸리는 순간까지 정확도를 높인다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;이후 최종 결과를 평가하고 난 후에 정확도를 높이거나, infra를 증축하거나, 모델의 complexity를 줄이거나와 같은 대책을 마련하고 실행한다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;use-of-accelerators-in-serving-infrastructure&quot;&gt;&lt;strong&gt;Use of Accelerators in Serving Infrastructure&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220729225935034.png&quot; alt=&quot;image-20220729225935034&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Accelerator를 통해 infrastructure를 최적화할 수 있다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;GPU의 경우는 training 가속화에 강점을 보이며,&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;TPU는 large batch size, complex model inference에 강점이 있다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;maintaining-input-feature-lookup&quot;&gt;&lt;strong&gt;Maintaining Input Feature Lookup&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220729225942225.png&quot; alt=&quot;image-20220729225942225&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Prediction을 수행할 때에는 많은 feature들이 필요할 수 있다.&lt;/li&gt;
  &lt;li&gt;예를들어 음식 배달 시간을 예측한다고 할때, 주문 수, 현재 교통 상황, 처리되지 않은 주문 수와 같은 많은 정보들이 필요하다.&lt;/li&gt;
  &lt;li&gt;Prediction latency를 줄이기 위해서는 사용되는 대량의 정보를 data store에서 빠르게 읽을 수 있어야 한다.&lt;/li&gt;
  &lt;li&gt;이때 cache를 사용하면 필요한 정보를 빠르게 읽어 latency를 낮출 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;nosql-databases-caching-and-feature-lookup&quot;&gt;&lt;strong&gt;NoSQL Databases: Caching and Feature Lookup&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220729225950122.png&quot; alt=&quot;image-20220729225950122&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;NoSQL은 caching과 feature look up을 구현하기에 좋으며, 위와 같이 다양한 옵션들이 존재한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;</content><author><name>Jaeseo Yu</name></author><category term="Lecture" /><category term="mlops" /><category term="deep learning" /><category term="machine learning" /><category term="lecture summary" /><summary type="html">Model serving 인프라에서 고려해야할 점들에 대한 내용을 알아본다.</summary></entry><entry><title type="html">Deploying Machine Learning Models in Production_Introduction to Model Serving</title><link href="http://localhost:4000/lecture/2022/07/28/Deploying-Machine-Learning-Models-in-Production-Introduction-to-Model-Serving/" rel="alternate" type="text/html" title="Deploying Machine Learning Models in Production_Introduction to Model Serving" /><published>2022-07-28T00:00:00+09:00</published><updated>2022-07-28T00:00:00+09:00</updated><id>http://localhost:4000/lecture/2022/07/28/%5BDeploying%20Machine%20Learning%20Models%20in%20Production%5D%20Introduction%20to%20Model%20Serving</id><content type="html" xml:base="http://localhost:4000/lecture/2022/07/28/Deploying-Machine-Learning-Models-in-Production-Introduction-to-Model-Serving/">&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;what-exactly-is-serving-a-model&quot;&gt;&lt;strong&gt;What exactly is Serving a Model?&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction%20to%20Model%20Serving/what%20exactly%20is%20Serving%20a%20Model.png&quot; alt=&quot;image&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;전체 ML 프로젝트에서 model training은 우리가 아는 굉장히 일부분이다.&lt;/li&gt;
  &lt;li&gt;그중 model serving은 학습시킨 model을 end user가 사용할 수 있도록 하는 것이며,&lt;/li&gt;
  &lt;li&gt;이를 위해서는 end user가 interaction할 수 있는 app 또는 서비스가 필요하다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;model-serving-patterns&quot;&gt;&lt;strong&gt;Model Serving patterns&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction%20to%20Model%20Serving/Model%20Serving%20patterns.png&quot; alt=&quot;image&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Inference는 모델에 입력 값을 넣고 예측을 하는 과정이며,&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;크게 세가지 (model, interpreter, input data)가 필요하다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;ml-workflows&quot;&gt;&lt;strong&gt;ML workflows&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction%20to%20Model%20Serving/ML%20workflows.png&quot; alt=&quot;image&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;ML workflow는 크게 &lt;strong&gt;model training&lt;/strong&gt;, &lt;strong&gt;model prediction&lt;/strong&gt; 두 가지로 나뉜다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;이때, model training은 &lt;strong&gt;offline learning(batch learning, static learning)&lt;/strong&gt;과 &lt;strong&gt;online learning(dynamic learning)&lt;/strong&gt;으로 나눌 수 있다.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Offline learning&lt;/strong&gt;
        &lt;ul&gt;
          &lt;li&gt;Offline learning은 일정 기간 동안 이미 수집된 데이터를 바탕으로 특정 시기에 모델 학습을 시키는 것이다.&lt;/li&gt;
          &lt;li&gt;즉 기존 data와 새로 들어온 data를 함께 학습시키게 되며 대량의 데이터를 한번에 처리하기 때문에 학습시 많은 시간과 자원이 소요된다.&lt;/li&gt;
          &lt;li&gt;모델을 배포하면 재학습시까지 모델은 고정된 상태가 되며, 오랜 시간이 지나면 새로운 pattern에 대응하지 못하며 &lt;strong&gt;model decay&lt;/strong&gt;가 발생한다.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Online learning&lt;/strong&gt;
        &lt;ul&gt;
          &lt;li&gt;Online learning 은 실시간으로 스트림 데이터가 들어올 때 마다 주기적으로 모델을 학습시키는 것이다.&lt;/li&gt;
          &lt;li&gt;주로 sensor, stock 데이터와 같은 time-series data을 토대로 학습을 할때 많이 활용한다.
&lt;br /&gt;&lt;br /&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Model prediction도 &lt;strong&gt;Batch prediction, Realtime prediction&lt;/strong&gt; 두 타입이 존재한다.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Batch prediction&lt;/strong&gt;
        &lt;ul&gt;
          &lt;li&gt;Batch prediction은 과거에 모인 다량의 데이터를 기반으로 예측을 하는것이다.&lt;/li&gt;
          &lt;li&gt;즉 한번의 예측에서 많은 수의 인스턴스를 처리하게 된다.&lt;/li&gt;
          &lt;li&gt;데이터가 time dependent하지 않고, realtime으로 예측을 하는 것이 중요하지 않은 상황에 적절하다.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Realtime prediction&lt;/strong&gt;
        &lt;ul&gt;
          &lt;li&gt;Real time prediction은 inference 요청이 온 시점에 들어온 데이터를 기반으로 실시간으로 prediction을 하는 것이다.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;important-metrics&quot;&gt;&lt;strong&gt;Important metrics&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction%20to%20Model%20Serving/Important%20metrics.png&quot; alt=&quot;image&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Online inference에서 중요하게 살펴보는 metric으로는 latency, throughput, cost가 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;lantency&quot;&gt;&lt;strong&gt;Lantency&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction%20to%20Model%20Serving/Lantency.png&quot; alt=&quot;image&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Latency는 user의 요청과 이에대한 application의 응답까지의 시간을 의미한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;throughput&quot;&gt;&lt;strong&gt;Throughput&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction%20to%20Model%20Serving/Throughput.png&quot; alt=&quot;image&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Throughput은 단위 시간동안 처리한 요청의 수를 의미한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;cost&quot;&gt;&lt;strong&gt;Cost&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction%20to%20Model%20Serving/Cost.png&quot; alt=&quot;image&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Serving infrastructure는 반드시 cost를 수반하게 된다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;minimizing-latency-maximizing-throughput&quot;&gt;&lt;strong&gt;Minimizing Latency, Maximizing Throughput&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction%20to%20Model%20Serving/Minimizing%20Latency,%20Maximizing%20Throughput.png&quot; alt=&quot;image&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;많은 기업들은 latency를 최소화하며, throughput을 최대화하길 원한다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;예를들어 항공사 추천 서비스가 있다고 할때, 유저의 요청에 빠르게 응답할 수 있어야하며, 공휴일과 같이 유저가 몰리는 시간에는 많은 요청을 빠르게 처리할 수 있어야 한다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;이러한 요건을 충족시키기 위해서는 infrastructure를 확장해야 하는데, 이때 큰 비용이 발생한다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;balance-cost-latency-and-throughput&quot;&gt;&lt;strong&gt;Balance Cost, Latency and Throughput&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction%20to%20Model%20Serving/Balance%20Cost,%20Latency%20and%20Throughput.png&quot; alt=&quot;image&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Infrastructure 확장에 많은 비용을 투자하지 않고 이러한 비용을 낮추기 위한 방법이 있다.
    &lt;ul&gt;
      &lt;li&gt;GPU 자원 공유&lt;/li&gt;
      &lt;li&gt;Multi model serving&lt;/li&gt;
      &lt;li&gt;Model optimization&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>Jaeseo Yu</name></author><category term="Lecture" /><category term="mlops" /><category term="deep learning" /><category term="machine learning" /><category term="lecture summary" /><summary type="html">Model serving이란 무엇이며, 중요하게 고려해야할 metric에 대해 알아본다.</summary></entry><entry><title type="html">Multithreading vs. Multiprocessing</title><link href="http://localhost:4000/operating%20system/2021/09/19/Multiprocess&multithread/" rel="alternate" type="text/html" title="Multithreading vs. Multiprocessing" /><published>2021-09-19T00:00:00+09:00</published><updated>2021-09-19T00:00:00+09:00</updated><id>http://localhost:4000/operating%20system/2021/09/19/%20Multiprocess&amp;multithread</id><content type="html" xml:base="http://localhost:4000/operating%20system/2021/09/19/Multiprocess&amp;multithread/">&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;process&quot;&gt;&lt;strong&gt;Process&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;프로세스는 실행중인 프로그램이다.&lt;/strong&gt; 즉 프로그램 자체는 프로세스가 아니라, 프로그램이 메모리에 올라가서 실행중일 때 프로세스가 되는 것이다. 프로세스는 크게 5가지 영역(text, stack, data, heap, program counter)로 나눌 수 있다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Text : Program code&lt;/li&gt;
  &lt;li&gt;Stack : Temporary data (function parameter, return addresses, local variables, etc)&lt;/li&gt;
  &lt;li&gt;Data : Static &amp;amp; global variables&lt;/li&gt;
  &lt;li&gt;Heap : Dynamic allocation&lt;/li&gt;
  &lt;li&gt;Program counter &amp;amp; registers : Current activity&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;https://www.tutorialspoint.com/operating_system/images/process_components.jpg&quot; alt=&quot;image&quot; width=&quot;45%&quot; height=&quot;45%&quot; class=&quot;align-center&quot; /&gt;
&lt;em&gt;Figure 1. Process in memory (&lt;a href=&quot;https://www.tutorialspoint.com/operating_system/os_processes.htm&quot;&gt;source&lt;/a&gt;)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;thread&quot;&gt;&lt;strong&gt;Thread&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Thread는 프로세스 내에서 실행되는 단위를 말한다.&lt;/strong&gt; 일반적으로 한 프로세스는 하나의 스레드를 가지고 있지만, 프로그램 환경에 따라 둘 이상의 thread를 동시에 실행시킬 수 있다. 각 Thread는 program counter, register set, stack space를 별도로 지니고 있다. 반면, 각 thread는 프로세스 내 code, data, heap, file과 같은 operating system 자원을 공유하게 된다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;https://www.tutorialspoint.com/operating_system/images/thread_processes.jpg&quot; alt=&quot;image&quot; width=&quot;90%&quot; height=&quot;90%&quot; class=&quot;align-center&quot; /&gt;
&lt;em&gt;Figure 2. Single thread vs Multithreads (&lt;a href=&quot;https://www.tutorialspoint.com/operating_system/os_multi_threading.htm&quot;&gt;source&lt;/a&gt;)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;multithreading-multiprocessing-비교&quot;&gt;&lt;strong&gt;Multithreading, multiprocessing 비교&lt;/strong&gt;&lt;/h2&gt;
&lt;h3 id=&quot;multithreading--장점&quot;&gt;&lt;strong&gt;Multithreading : 장점&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Thread 간 Resource sharing이 가능하다.
    &lt;ul&gt;
      &lt;li&gt;동일 프로세스 내 thread 간 데이터를 공유할 수 있다. 만약 subset으로 나누기 어려운 대량의 데이터를 다뤄야 할 경우, 데이터를 복사하거나 shared memory 방식을 사용해서 프로세스 간 데이터를 전송 또는 공유해야 한다. 하지만 데이터 복사는 복사 시 추가 시간과 메모리를 소요하게 되며, shared memory의 경우에는 개발 시 고려해야 될 요소들이 많다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;소요되는 자원이 더 적다.
    &lt;ul&gt;
      &lt;li&gt;Thread를 하나 생성하는 것 보다 process를 생성할 때 소요되는 시간과 자원이 훨씬 더 많이 들어간다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;multithreading--단점&quot;&gt;&lt;strong&gt;Multithreading : 단점&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;안정성이 떨어진다.
    &lt;ul&gt;
      &lt;li&gt;만약 여러 thread 들 중 단 하나의 thread라도 문제가 발생할 경우, application이 crash된다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;디버깅 하기 어렵다.
    &lt;ul&gt;
      &lt;li&gt;Multithread 환경에서 디버거를 통해 버그의 원인을 발견하기 어렵다. 따라서 문제가 되는 thread를 발견하기 위해 보통 log를 찾아보며 추적하게 됨으로, 디버깅에 소요되는 시간이 많이 들어가게 된다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;multiprocessing--장점&quot;&gt;&lt;strong&gt;Multiprocessing : 장점&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;안정성이 높다.
    &lt;ul&gt;
      &lt;li&gt;여러 프로세스 실행 중 하나의 프로세스에 문제가 발생할 경우, 해당 프로세스만 종료시키면 된다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;확장성이 크다.
    &lt;ul&gt;
      &lt;li&gt;프로세스는 다른 머신에 할당해서 실행할 수가 있다. 반면에 thread는 단일 프로세스 내에 존재해야 하므로 확장성이 떨어질 수밖에 없다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;multiprocessing--단점&quot;&gt;&lt;strong&gt;Multiprocessing : 단점&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;프로세스 간 커뮤니케션이 복잡하다.
    &lt;ul&gt;
      &lt;li&gt;프로세스 간 데이터를 공유할 때는 별도의 technique (shared memory 또는 inter process communication)을 사용해야 하기 때문이다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;메모리 소요가 크다.
    &lt;ul&gt;
      &lt;li&gt;프로세스 간에는 별도의 독립된 메모리 영역을 갖는다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;</content><author><name>Jaeseo Yu</name></author><category term="Operating system" /><category term="operating system" /><category term="parallel programming" /><summary type="html">Multithreading과 multiprocessing 장단점에 대한 간략한 정리</summary></entry><entry><title type="html">프로그래머스 - 기둥과 보 설치</title><link href="http://localhost:4000/algorithm/2021/09/18/programmers%EA%B8%B0%EB%91%A5%EA%B3%BC%EB%B3%B4%EC%84%A4%EC%B9%98/" rel="alternate" type="text/html" title="프로그래머스 - 기둥과 보 설치" /><published>2021-09-18T00:00:00+09:00</published><updated>2021-09-18T00:00:00+09:00</updated><id>http://localhost:4000/algorithm/2021/09/18/programmers%EA%B8%B0%EB%91%A5%EA%B3%BC%EB%B3%B4%EC%84%A4%EC%B9%98</id><content type="html" xml:base="http://localhost:4000/algorithm/2021/09/18/programmers%EA%B8%B0%EB%91%A5%EA%B3%BC%EB%B3%B4%EC%84%A4%EC%B9%98/">&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;problem&quot;&gt;&lt;strong&gt;Problem&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://programmers.co.kr/learn/courses/30/lessons/60061&quot;&gt;2020 KAKAO BLIND RECRUITMENT 기둥과 보 설치&lt;/a&gt;
&lt;br /&gt;&lt;br /&gt;
문제는 2차원 공간에 구조물 (기둥 or 보)를 설치/삭제 한 후 최종 구조물의 상태를 return 하는 것이다. 구조물의 정보&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(x 좌표, y좌표, 구조물 종류, 설치/삭제)&lt;/code&gt;들을 담은 2차원 배열이 입력되고, 최종 구조물의 상태&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(x 좌표, y 좌표, 구조물 종류)&lt;/code&gt;를 반환하면 된다. 단, 문제에 나온 &lt;strong&gt;특정 조건을 만족해야만 주어진 위치에 기둥과 보를 설치/삭제할 수 있다는 점에 유의&lt;/strong&gt;해야 한다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;solution&quot;&gt;&lt;strong&gt;Solution&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;보와 기둥의 존재 여부를 나타내는 2차원 배열을 각각 만들고, 현재 특정 위치에 구조물이 존재하는 지를 표시한다. 구현할 때, 구조물 설치/삭제 입력에 대해 설치와 삭제 시에 만족해야 하는 특정 조건을 검사하는 것이 까다롭다. 기둥과 보가 존재하기 위해서는 각각의 조건을 만족해야 한다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;기둥
    &lt;ul&gt;
      &lt;li&gt;바닥 위에 존재&lt;/li&gt;
      &lt;li&gt;왼쪽/오른쪽 보의 끝 위에 존재&lt;/li&gt;
      &lt;li&gt;다른 기둥 위에 존재&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;보
    &lt;ul&gt;
      &lt;li&gt;왼쪽/오른쪽 끝 부분이 기둥 위에 존재&lt;/li&gt;
      &lt;li&gt;양쪽 끝 부분이 다른 보와 동시에 연결&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;설치 시에는 위의 조건을 만족하는 지 확인하고, 만족할 경우 설치를 해주면 된다. 반면 삭제할 때는 삭제하려는 기둥, 보의 존재 여부에 영향을 받는 기둥, 보에 대해 위의 유효 조건을 검사해야 한다. 조건을 만족하지 않을 경우 삭제를 할 수 없으므로, 구조물 삭제를 취소해야 한다. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x,y&lt;/code&gt; 좌표에 있는 기둥 또는 보 삭제 시 영향을 받는 구조물은 다음과 같다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;기둥 (x, y)
    &lt;ul&gt;
      &lt;li&gt;바로 위에 존재하는 기둥 (x, y+1)&lt;/li&gt;
      &lt;li&gt;오른쪽 끝이 기둥 위에 존재하는 보 (x-1, y+1)&lt;/li&gt;
      &lt;li&gt;왼쪽 끝이 기둥 위에 존재하는 보 (x, y+1)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;보 (x, y)
    &lt;ul&gt;
      &lt;li&gt;왼쪽 끝 위에 존재하는 기둥 (x, y)&lt;/li&gt;
      &lt;li&gt;오른쪽 끝 위에 존재하는 기둥 (x+1, y)&lt;/li&gt;
      &lt;li&gt;왼쪽 끝에 닿아있는 보 (x-1, y)&lt;/li&gt;
      &lt;li&gt;오른쪽 끝에 닿아있는 보 (x+1, y)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;해당 위치에 있는 특정 기둥과 보만을 검사하면, 모든 구조물을 검사하지 않고 삭제가 가능한지 효과적으로 판단할 수 있다. 주의해야 할 점은, 검사해야 하는 위치에 구조물이 있을 경우에만 유효성 검사를 해야 하는 것이다. 이점을 신경쓰지 못해서 모든 케이스를 통과하는 데 많은 시간이 걸렸다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;code&quot;&gt;&lt;strong&gt;Code&lt;/strong&gt;&lt;/h2&gt;
&lt;div class=&quot;language-c++ highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;#include &amp;lt;vector&amp;gt;
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;namespace&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;101&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;101&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// 기둥 놓을 수 있는지 확인&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;check_0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// 보 놓을 수 있는지 확인&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;check_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])){&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// 기둥 지울 수 있는지 확인&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;check_d_0&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;check_0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;check_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;check_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))){&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// 보 지울 수 있는지 확인 &lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;check_d_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;check_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;check_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;check_0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;check_0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))){&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;construct&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;check_0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)){&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;check_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;deconstruct&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;check_d_0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;check_d_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;solution&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;build_frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;answer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;build_frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
        &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;build_frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
        &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;build_frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
        &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;build_frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
        &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;build_frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;construct&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;deconstruct&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;each_0&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;each_1&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
            
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;each_0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;each_0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;each_0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;answer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;push_back&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;each_0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
            
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]){&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;each_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;each_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;each_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;answer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;push_back&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;each_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;answer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;</content><author><name>Jaeseo Yu</name></author><category term="Algorithm" /><category term="algorithm" /><category term="c++" /><category term="online judge" /><category term="구현/시뮬레이션" /><category term="programmers" /><summary type="html">프로그래머스 구현 문제인 기둥과 보 설치 문제 풀이 및 코드에 대한 정리</summary></entry><entry><title type="html">백준(10816) - 숫자 카드2</title><link href="http://localhost:4000/algorithm/2021/09/16/Baekjoon10816/" rel="alternate" type="text/html" title="백준(10816) - 숫자 카드2" /><published>2021-09-16T00:00:00+09:00</published><updated>2021-09-16T00:00:00+09:00</updated><id>http://localhost:4000/algorithm/2021/09/16/Baekjoon10816</id><content type="html" xml:base="http://localhost:4000/algorithm/2021/09/16/Baekjoon10816/">&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;problem&quot;&gt;&lt;strong&gt;Problem&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Baekjoon-10816.png&quot; alt=&quot;image&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;
&lt;em&gt;Figure 1. 백준 10816 숫자 카드2 (&lt;a href=&quot;https://www.acmicpc.net/problem/10816&quot;&gt;source&lt;/a&gt;)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;solution&quot;&gt;&lt;strong&gt;Solution&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;문제는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;N&lt;/code&gt;개의 정수 입력이 주어졌을 때, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;M&lt;/code&gt;개의 특정 숫자가 나온 빈도 수를 출력하는 것이다.
숫자의 범위가 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(-10,000,000 &amp;lt;= x &amp;lt;= 10,000,000)&lt;/code&gt; 밖에 안되기 때문에, 가장 간단한 풀이는 x에 최소값을 더해 양수로 변환한 후 배열에 각 숫자가 발생한 빈도를 count하는 것이다. 
다른 방법은 binary search를 응용하는 방법인데, 입력 배열을 오름차순으로 정렬한 다음 아래와 같이 &lt;strong&gt;특정 숫자가 나타나는 범위(lower bound, upper bound)&lt;/strong&gt;를 구해서 푸는 방법이다.
첫번째 방법은 숫자의 범위가 수십억 등 더 큰 단위로 커질 경우 메모리를 많이 사용해야 되며, 대부분의 사람들이 스스로 잘 풀 것이라고 생각한다. 
따라서, 개인적으로 정리도 하는 겸 두번째 방법으로 푸는 방법에 대해 소개하려고 한다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;lower-bound&quot;&gt;&lt;strong&gt;Lower bound&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Lower bound는 특정 값(key)보다 크거나 같은 값의 첫번째 위치를 나타낸다. lower bound 값을 찾기 위해서 binary search와 같이 탐색 공간을 반복적으로 절반씩 줄여 나간다. 이때 주의해야 할 것은 탐색 공간을 줄일 때 right와 left의 값을 어떻게 설정하는 지이다. key 값보다 mid 위치의 값이 크거나 같은 경우 lower bound는 mid의 왼편에 존재하게 되는데, 이때 mid가 lower bound가 될 수 있기 때문에, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;right = mid&lt;/code&gt;로 설정해준다. 반면에 key 값이 mid 위치의 값 보다 큰 경우, mid가 lower bound가 될 가능성이 없기 때문에 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;left = mid + 1&lt;/code&gt;으로 설정한다. 이러한 과정을 lower &amp;lt; right 조건이 만족하는 경우에 한해 반복하고, loop가 끝나면 left 값을 반환하게 된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Baekjoon-10816/Lower-bound1.PNG&quot; alt=&quot;image&quot; width=&quot;85%&quot; height=&quot;70%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Baekjoon-10816/Lower-bound2.PNG&quot; alt=&quot;image&quot; width=&quot;85%&quot; height=&quot;70%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Baekjoon-10816/Lower-bound3.PNG&quot; alt=&quot;image&quot; width=&quot;85%&quot; height=&quot;70%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Baekjoon-10816/Lower-bound4.PNG&quot; alt=&quot;image&quot; width=&quot;85%&quot; height=&quot;70%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Baekjoon-10816/Lower-bound5.PNG&quot; alt=&quot;image&quot; width=&quot;85%&quot; height=&quot;70%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;upper-bound&quot;&gt;&lt;strong&gt;Upper bound&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Upper bound는 특정 값(key)보다 큰 값이 처음으로 나오는 위치를 나타낸다. 만약 key 값이 mid 위치의 값보다 작은 경우 mid가 upper bound가 될 수 있으므로, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;right = mid&lt;/code&gt;로 설정한다. 반면에 key 값이 mid 위치 값보다 크거나 같은 경우, mid가 upper bound가 될 수 없기 때문에 left를 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mid + 1&lt;/code&gt;으로 설정한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Baekjoon-10816/Upper-bound1.PNG&quot; alt=&quot;image&quot; width=&quot;85%&quot; height=&quot;70%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Baekjoon-10816/Upper-bound2.PNG&quot; alt=&quot;image&quot; width=&quot;85%&quot; height=&quot;70%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Baekjoon-10816/Upper-bound3.PNG&quot; alt=&quot;image&quot; width=&quot;85%&quot; height=&quot;70%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Baekjoon-10816/Upper-bound4.PNG&quot; alt=&quot;image&quot; width=&quot;85%&quot; height=&quot;70%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;code&quot;&gt;&lt;strong&gt;Code&lt;/strong&gt;&lt;/h2&gt;
&lt;div class=&quot;language-c++ highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;algorithm&amp;gt;
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;namespace&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;500001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;M&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;upperbound&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
	&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	
	&lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;mid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

	&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;lowerbound&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
	&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	
	&lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;mid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

	&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;ios_base&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sync_with_stdio&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tie&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tie&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

	&lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

	&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

	&lt;span class=&quot;n&quot;&gt;sort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

	&lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;M&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

	&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;M&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
		&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
		
		&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lower_idx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lowerbound&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
		&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;upper_idx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;upperbound&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

		&lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;upper_idx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lower_idx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot; &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

	&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;time-complexity&quot;&gt;&lt;strong&gt;Time complexity&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Sorting과 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;2M&lt;/code&gt;번의 binary search 시간을 더하여 $O( (N+M)log{N} )$&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;</content><author><name>Jaeseo Yu</name></author><category term="Algorithm" /><category term="algorithm" /><category term="c++" /><category term="online judge" /><category term="binary search" /><category term="baekjoon" /><summary type="html">Binary search를 응용한 lower bound, upper bound를 찾는 방법에 대해 알아본다.</summary></entry><entry><title type="html">OpenCL과 4가지 모델</title><link href="http://localhost:4000/opencl/2021/08/30/OpenCL%EC%9D%B4%EB%9E%80/" rel="alternate" type="text/html" title="OpenCL과 4가지 모델" /><published>2021-08-30T00:00:00+09:00</published><updated>2021-08-30T00:00:00+09:00</updated><id>http://localhost:4000/opencl/2021/08/30/%20OpenCL%EC%9D%B4%EB%9E%80</id><content type="html" xml:base="http://localhost:4000/opencl/2021/08/30/OpenCL%EC%9D%B4%EB%9E%80/">&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;1opencl&quot;&gt;1.OpenCL&lt;/h1&gt;

&lt;p&gt;&lt;br /&gt;
&lt;strong&gt;OpenCL(Open Computing Language)&lt;/strong&gt;은 CPU, GPU, DSP 등 다양한 하드웨어 자원을 활용하여 프로그래밍을 하기 위한 산업 표준 병렬 프레임워크이다. 비영리 컨소시엄인 크로노스 그룹(Khronos Group)이 관리하고 있으며 여러 제조사에서 만들어진 하드웨어로 이루어진 시스템에까지 효과적으로 활용될 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;2opencl-4가지-모델&quot;&gt;2.OpenCL 4가지 모델&lt;/h1&gt;

&lt;p&gt;&lt;br /&gt;
OpenCL의 architecture를 4가지 개념적 모델로서 구분하여 설명한다. 
&lt;br /&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;ol&gt;
    &lt;li&gt;Platform model&lt;/li&gt;
    &lt;li&gt;Execution model&lt;/li&gt;
    &lt;li&gt;Memory model&lt;/li&gt;
    &lt;li&gt;Programming model&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;2-1-platform-model&quot;&gt;2-1. Platform model&lt;/h2&gt;
&lt;p&gt;&lt;br /&gt;
 OpenCL에서 사용되는 heterogeneous한 platform들을 high-level한 관점에서 나타낸 것이다. host와 device들로 구성되어 있으며 host는 OpenCL 외부 환경과의 상호작용을 담당한다. 예를 들어 I/O나 프로그램 유저와의 소통 창구 역할을 하는 것이다. 이러한 host는 여러 OpenCL device들과 연결되어 있다. 이러한 device는 compute device로 불리기도 하며, CPU, GPU, DSP등 여러 프로세서를 포함한다. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;OpenCL device&lt;/code&gt;는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;compute units&lt;/code&gt;로 나뉘고 이는 다시 실제 연산이 수행되는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;processing elements(PEs)&lt;/code&gt;로 나뉘게 된다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;2-2-execution-model&quot;&gt;2-2. Execution model&lt;/h2&gt;
&lt;p&gt;&lt;br /&gt;
&lt;strong&gt;OpenCL execution model은 어떻게 kernel이 실행되는지를 정의한다.&lt;/strong&gt; OpenCL application은 host program과 하나 이상의 kernels로 이루어져 있다. kernel들은 OpenCL device에서 실행되며 input memory object를 입력받아 처리를 거친 후 output memory object를 리턴한다.&lt;/p&gt;

&lt;p&gt;Host program은 OpenCL device에 kernel을 할당하는 명령어를 실행한다. 그러면 OpenCL 런타임은 integer index space를 만들고 각 kernel의 instance들이 해당 index space위에서 실행된다. 이렇게 실행중인 kernel을 &lt;strong&gt;work-item&lt;/strong&gt;이라고 부른다. 그리고 이 work-item들이 모여서 &lt;strong&gt;work-group&lt;/strong&gt;을 구성하게 된다. work-item과 work-group은 고유의 id 값을 가지며 각 work-item은 해당 아이템이 속한 work-group 내에서 마찬가지로 id를 가진다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;+커널은 어떻게 실행이 되는가?&lt;/strong&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Kernel을 실행하기 위해서는 먼저 각 device마다 할당되어 있는 queue에 해당 &lt;em&gt;kernel&lt;/em&gt;을 enqueue해야 한다. 이 때 사용하는 OpenCL API는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;enqueueNDRangeKernel()&lt;/code&gt;이다. 해당 API를 호출할 때 핵심적인 3가지 arguments는 Kernel object, work-items의 수(global size), work-group당 work-item의 수 (local size)이다. 해당 명령어를 통해 host program이 OpenCL device에 실행되어야 할 kernel을 전달하게 되고 OpenCL runtime은 integer index space를 구성하게 된다. 실행 중인 kernel을 &lt;em&gt;work item&lt;/em&gt;이라고 하며 동일한 instruction sequence를 갖는다.이는 index 공간의 좌표를 통해 식별된다. 이러한 좌표는 work-item의 global id이다. work item들이 모여서 &lt;em&gt;work group&lt;/em&gt;을 형성하게 된다. work group은 대응되는 각 dimension에 대해 같은 size를 갖고 global size를 균등하게 나누게 된다. work-group내의 work-item은 단일 compute unit의 processing unit들에서 &lt;em&gt;concurrent&lt;/em&gt;하게 실행된다. index space는 N-dimension을 갖는 일정 값의 범위에 존재하는데, 이를 &lt;em&gt;NDRange&lt;/em&gt;라고 부른다. 그리고 N은 1,2,3 으로 설정될 수 있다. NDRange는 길이 N의 integer array이며 각 element는 각 dimension의 index space의 size를 의미한다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;// Q라는 queue에 K라는 kernel object를 넣는다. 
Q.enqueueNDRangeKernel(K, NullRange, NDRange(1024), NDRange(128));
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;br /&gt;
&lt;br /&gt;
위의 코드는 1024개의 work-item을 생성하고 각 work-group에 128개의 work-item을 할당한다. 따라서 1024/128 = 8개의 work-group이 생성되게 된다.
&lt;br /&gt;
OpenCL C kernel 코드는 single work-item에 대응된다. work-item의 granuality는 프로그래머가 필요에 따라 설정하게 된다. 아래는 1024개의 elements를 담은 두 array의 합을 구하는 kernel 코드이다.&lt;/p&gt;

&lt;p&gt;1) work-item마다 1개의 array element를 더하는 예제
&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kernel vectorAdd(global int* A, global const int * B)
{
    int gid = get_global_id(0);
    A[gid] += B[gid];
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;br /&gt;
2) work-item마다 16개의 array elements을 더하는 예제
&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#define ITER 16

kernel vectorAdd(global int* A, global const int * B)
{
    int gid = get_global_id(0) * ITER;
    int i;
    for (i = 0; i &amp;lt; ITER; ++i)
    {
        A[gid + i] += B[gid+ i];
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;첫번째 예제는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;enqueueNDRangeKernel()&lt;/code&gt;를 호출할 때 1024를 global size로 설정한다. 두 번째 kernel은 각 work-item마다 16개의 elements를 더하기 때문에 64(1024/16)를 global size로 설정한다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Work-group 실행&lt;/strong&gt;
&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Event ev;
Q.enqueueNDRangeKernel(K, NullRange, NDRange(8), NDRange(1), NULL, &amp;amp;ev);
concurrent();
ev.wait()
post();
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;2번째 code line이 실행되면, kernel이 command-queue Q에 들어간다. 그리고 해당 command가 return 하고 나서 3번째 줄의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;conccurent()&lt;/code&gt;가 실행된다.&lt;/p&gt;

&lt;p&gt;이 때 비동기적으로 OpenCL runtime은 command-queue를 모니터링한다. command-queue에 kernel이 들어오고 모든 dependencies가 만족된 상태이면 요청된 kernel에 맞는 수의 work-groups을 생성한 후 command-queue와 연결된 device의 work-group queue에 넣는다.&lt;/p&gt;

&lt;p&gt;각 device의 core(compute unit)는 device에 할당된 &lt;em&gt;work-group queue&lt;/em&gt;에서 work-group을 뽑는다. 그리고 뽑은 work-group을 각 compute unit에서 실행시키며, queue에 있는 모든 work-group을 전부 뽑을 때 까지 이 과정을 반복한다.&lt;/p&gt;

&lt;p&gt;host CPU는 concurrent()를 실행하고 다른 프로세서(ex. DSP)의 cores는 concurrently work-group들을 실행하게 된다. 만약 host가 concurrent 함수를 먼저 끝냈다고 할 때, 4번째 command가 실행되게 된다. 이 때 kernel submission과 관련된 ev가 CL_COMPLETE가 될 때까지 host는 wait을 하게 된다. 이후 OpenCL runtime은 kernel K에 대한 모든 work-group들이 완료되면 ev의 status를 CL_COMPLETE로 변환하게 되고 host가 5번째 command인 post()를 실행하게 된다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Work-group 내의 Work-item 실행&lt;/strong&gt;
&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;앞에서 말했듯이 kernel function은 single work-item에 대응된다. 해당 work-item들이 실행되는 device의 hardware architecture에 따라 work-item의 수행에 대한 OpenCL 구현이 다르다. 어떠한 architecture에서는 work-item이 concurrently하게 실행되고 어떤 architecture에서는 sequentially하게 수행된다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Context&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Context&lt;/em&gt;는 kernel이 정의되고 실행되는 환경을 정의한다. host는 kernel을 정의하고 이에 맞는 context를 생성한다. Context는 아래의 4가지 요소의 측면에서 정의된다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Devices&lt;/li&gt;
  &lt;li&gt;Kernels&lt;/li&gt;
  &lt;li&gt;Program objects&lt;/li&gt;
  &lt;li&gt;Memory objects&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;Context&lt;/em&gt;는 host가 OpenCL API를 이용하여 생성하고 조작한다. host는 cpu 내의 특정 core에서 작동하게 된다. host는 heterogeneous platform 내에서 어떤 하드웨어 자원이 사용 가능한지 파악한다. 그리고 host는 실행해야 할 kernel과 문제에 맞게 하드웨어 자원의 조합을 결정한다. 이후 host는 선택된 devices를 context내에 정의하게 된다.&lt;/p&gt;

&lt;p&gt;또한 하나 이상의 &lt;em&gt;Program objects&lt;/em&gt;이 context에 포함된다. Program object는 kernel을 구현한 source code와 executables을 담고 있다. 이러한 program object는 runtime에 생성된다. runtime에 object가 생성되는 이유는 OpenCL 개발자들은 end user가 어떠한 하드웨어 자원 위에서 프로그램을 실행할지 모르기 때문이다. 따라서 context에 devices가 정의되면, host는 이에 맞게 source code를 컴파일하는 방법을 정하게 되고 kernel를 위한 코드를 생성하게 된다.&lt;/p&gt;

&lt;p&gt;마지막으로 kernel 코드를 실행하는데 필요한 메모리 자원이 필요하다. 하지만 devices들은 저마다 서로 다른 memory architecture를 가지고 있으며 이러한 문제에 대처하기 위해서 OpenCL은 &lt;em&gt;Memory objects&lt;/em&gt; 라는 개념을 정의하고 사용한다. 이 objects는 host에서 정의되며 devices 간, host와 device 사이에서 필요에 의해 전달되며 사용된다. memory objects의 개념으로 OpenCL은 더 많고 다양한 platform을 지원할 수 있게 된다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Memory Model&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;OpenCL은 *buffer objects&lt;/em&gt;와 &lt;em&gt;image object&lt;/em&gt;라는 2가지 타입의 memory object를 정의한다. 이는 kernel이 사용할 수 있는 contiguous한 메모리 블록이다. Image object는 OpenCL의 built-in support로서 다양한 format의 image data를 처리하는 과정에서 데이터 표현과 접근을 더 쉽고 간단하게 해준다. OpenCL model은 메모리 영역을 5가지로 구분한다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Host memory : Host에게만 보이는 메모리 영역이다.&lt;/li&gt;
  &lt;li&gt;Global memory : 모든 work-group의 모든 work-item들이 read/write 접근을 할 수 있는 메모리 영역이다.&lt;/li&gt;
  &lt;li&gt;Constant memory : Global memory 영역에 속해있는 영역으로서 kernel 실행 동안 constant하게 유지된다. host가 constant memory를 할당하고 초기화하며 work-item은 해당 영역의 objects에 read-only access만 가능하다.&lt;/li&gt;
  &lt;li&gt;Local memory : 이 메모리 영역은 work-group에 속한다. 따라서 이 영역의 variable들은 특정 work-group의 work-item들 간에 공유가 된다.&lt;/li&gt;
  &lt;li&gt;Private memory : 이 메모리 영역은 특정 work-item을 위하여 할당되며 다른 work-item은 해당 영역을 볼 수 없다.&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Jaeseo Yu</name></author><category term="OpenCL" /><category term="parallel programming" /><category term="opencl" /><summary type="html">OpenCL의 architecture를 구성하는 4가지 개념적 모델에 대해 알아본다.</summary></entry><entry><title type="html">CNN (Convolutional Neural Networks)에 대한 기본적인 내용 정리</title><link href="http://localhost:4000/deep%20learning/2021/08/13/About-CNN/" rel="alternate" type="text/html" title="CNN (Convolutional Neural Networks)에 대한 기본적인 내용 정리" /><published>2021-08-13T00:00:00+09:00</published><updated>2021-08-13T00:00:00+09:00</updated><id>http://localhost:4000/deep%20learning/2021/08/13/About%20CNN</id><content type="html" xml:base="http://localhost:4000/deep%20learning/2021/08/13/About-CNN/">&lt;hr /&gt;

&lt;h2 id=&quot;cnn-convolutional-neural-networks-이란&quot;&gt;&lt;strong&gt;CNN (Convolutional Neural Networks) 이란?&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;CNN 모델은 convolution 연산을 활용하는 neural networks의 한 종류이다. 즉, neural network 모델 내 적어도 최소 한 개의 layer에서 convolution 연산이 사용될 경우 이를 CNN 모델이라고 할 수 있다. CNN은 보통 이미지 내의 특정 물체 또는 특징들을 발견하고 이해하는 컴퓨터비전 분야의 여러 task (Image detection, classification 등)에서 주로 사용된다.&lt;/p&gt;

&lt;h3 id=&quot;convolution-operation&quot;&gt;&lt;strong&gt;Convolution operation&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;Convolution 연산은 사각형 모양의 2차원 filter를 input matrix 위로 sliding하며 수행된다. Figure 1에서와 같이 filter가 input의 왼쪽에서 오른쪽으로 이동하며 오른쪽 끝에 도달하면 그 다음 행의 왼쪽 부터 다시 sliding을 시작한다. 이때 특정 위치마다 filter를 적용하게 되는데, filter와 input의 각 pixel에 대응되는 값끼리 곱한 후 이를 합하여 단일 output을 산출하게 한다. 그러면 이러한 convolution 연산은 왜 사용하게 되는 것일까.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;https://miro.medium.com/max/875/1*VVvdh-BUKFh2pwDD0kPeRA@2x.gif&quot; alt=&quot;image&quot; width=&quot;70%&quot; height=&quot;70%&quot; class=&quot;align-center&quot; /&gt;
&lt;em&gt;Figure 1. Convolution operation (&lt;a href=&quot;https://towardsdatascience.com/applied-deep-learning-part-4-convolutional-neural-networks-584bc134c1e2&quot;&gt;source&lt;/a&gt;)&lt;/em&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Convolution을 사용하는 이유는 컴퓨터가 이미지 내에 존재하는 특정 물체에 대한 특징을 효과적으로 추출하기 위해서이다. 이미지 분류 task를 예로 들면, 만약 컴퓨터가 특정 이미지가 사람의 이미지 인지를 분류하기 위해서는 사람이 나온 이미지들의 특성을 파악하고, input으로 주어지는 이미지에 해당 특성이 나타나는 지를 판단해야 한다. 사람이 사람 이미지 특성을 직접 컴퓨터에 입력할 수 있지만, 사람들 간의 다양성을 모두 반영한 특성을 파악하기란 쉽지 않다. 하지만, 우리는 딥러닝 모델이 데이터를 통해 컴퓨터가 직접 사람의 특성을 학습하고 이를 통해 분류를 자동으로 하도록 할 수 있다.&lt;/p&gt;

&lt;p&gt;그렇다면, fully connected layer를 통해 이미지 내의 특징을 추출할 수 는 없을까. 결과적으로 convolution 연산이 컴퓨터비전 분야에 더 적합하다. 그 이유는 convolution 연산이 2차원 input에서 feature를 더 잘 찾기 때문이다. Convolution 연산은 데이터의 형상을 보존하기 때문에, 이미지 데이터의 공간적인 정보를 반영하여 정보를 추출할 수 있다. Fully connected layer의 경우는 2차원 이미지가 주어질 때, 이를 1차원으로 flatten 하여 연산을 수행하기 때문에 데이터의 변환 과정에서 이미지 내의 공간적인 정보가 사라지게 된다.&lt;/p&gt;

&lt;p&gt;즉, 이미지의 특정 픽셀은 주변 픽셀과의 관계를 통해서 의미를 갖게 되기 때문에 feature 추출 시 이미지의 공간적인 정보를 보존하고 반영하는 것이 무엇보다 중요한 것이다. 하지만 fully connected layer는 특정 output을 산출하기 위해서 input의 모든 pixel을 반영하게 되는데, 이는 불필요한 정보까지 사용하여 학습을 하게 된다. 반면, convolution 연산 시 특정 neuron에게 전달되는 값은 모든 pixel이 아닌 특정 공간 내에 있는 pixel들로, feature 추출에 의미있는 pixel 값만을 사용하여 학습하게 된다.&lt;/p&gt;

&lt;p&gt;이와 같은 convolution operation을 수행하는 특정 layer를 convolution layer라고 하며, 다수의 convolution layer가 층층이 쌓여서 CNN 모델을 구성하게 된다. 이때 각 layer내에는 추출하고자 하는 feature 수에 따라 여러 개의 filter를 둘 수 있다. 각 convolution layer의 input을 input featrue map, output을 output feature map이라고 부른다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/assets/img/cnn%20spatial%20structure.png&quot; alt=&quot;image&quot; width=&quot;70%&quot; height=&quot;70%&quot; class=&quot;align-center&quot; /&gt;
&lt;em&gt;Figure 2. Feature extraction with convolution (&lt;a href=&quot;http://introtodeeplearning.com/slides/6S191_MIT_DeepLearning_L3.pdf&quot;&gt;source&lt;/a&gt;)&lt;/em&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;strides&quot;&gt;&lt;strong&gt;Strides&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;Strides는 convolution filter를 적용하는 위치 간격을 말한다. 만약 strides 설정 값이 2이면 필터를 각 차원(가로, 세로)에 대해서 두칸씩 움직이게 된다. Strides 간격이 1보다 클 경우는 filter가 이미지를 더 큰 간격으로 sliding하며 feature를 추출하기 때문에 subsample을 수행하는 것과 같은 역할을 한다. stides 크기는 보통 5, 3, 2, 1로 설정한다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;https://miro.medium.com/max/695/1*nGHLq1hx0gt02OK4l8WmRg.png&quot; alt=&quot;image&quot; width=&quot;70%&quot; height=&quot;70%&quot; class=&quot;align-center&quot; /&gt;
&lt;em&gt;Figure 3. Convolution with strides of 2 (&lt;a href=&quot;https://medium.com/@RaghavPrabhu/understanding-of-convolutional-neural-network-cnn-deep-learning-99760835f148&quot;&gt;source&lt;/a&gt;)&lt;/em&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;padding&quot;&gt;&lt;strong&gt;Padding&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;Padding은 입력 데이터 주변에 특정 값을 채우는 과정을 말한다. 데이터 주변에 추가적인 행/열을 추가하게 되며 보통 해당 위치에 0을 넣는다. Padding 적용 시 얻는 효과는 크게 세 가지가 있다. 첫번째는 output 차원이 급격히 줄어드는 것을 방지할 수 있다는 점이다. 두번째는 필터 학습 시 학습이 적게 될 수 있는 이미지 테두리 부분에서의 정보 손실을 줄일 수 있다는 점이다. 세번째는 strides 간격을 1보다 크게 설정할 경우, filter가 image 범위를 벗어나는 경우가 생기게 되는데, padding을 넣을 경우 이를 막아줄 수 있다는 것이다. Padding을 적용하지 않을 경우 이를 valid padding이라고 하며, 이때 filter는 input feature map 내에서만 sliding을 하게 된다. feature map 내에서만 sliding을 해야하기 때문에 input feature map의 오른쪽과 밑에 손실되는 정보가 발생하게 되며, strides의 크기에 따라 손실되는 정보의 양이 달라지게 된다. 반면, input과 output의 크기가 동일하도록 padding을 설정할 때 이를 same padding이라고 부른다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;https://miro.medium.com/max/741/1*1okwhewf5KCtIPaFib4XaA.gif&quot; alt=&quot;image&quot; width=&quot;60%&quot; height=&quot;60%&quot; class=&quot;align-center&quot; /&gt;
&lt;em&gt;Figure 4. Padding example (&lt;a href=&quot;https://towardsdatascience.com/types-of-convolutions-in-deep-learning-717013397f4d&quot;&gt;source&lt;/a&gt;)&lt;/em&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;그외-중요한-convolution-관련-연산&quot;&gt;&lt;strong&gt;그외 중요한 convolution 관련 연산&lt;/strong&gt;&lt;/h3&gt;

&lt;h4 id=&quot;pooling&quot;&gt;&lt;strong&gt;Pooling&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;Pooling은 input에서 subsampling을 수행하는 방법으로, input의 특정 영역에 있는 값들을 해당 영역의 statistics로 대체하게 된다. Average, max, min 등 여러 방법이 있으며, 최대 값을 취하는 max pooling이 일반적으로 많이 사용된다. Pooling을 사용하게 되면 input의 크기가 줄어들게 되며, 메모리 등 컴퓨터 자원을 아낄 수 있게 된다. 또한 pooling은 CNN 모델이 translation invariance한 성격을 갖도록 한다. 즉 만약 어떤 물체를 분류할 때, 물체의 위치가 어느 정도 변하여도 동일한 output을 내게 된다. translation invariance는 이미지에서 특정 feature가 존재하는 지 여부를 아는 것이 중요한 task일 때, 즉 물체의 위치를 아는 것이 중요하지 않을 때 필요한 중요한 성질이다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/assets/img/pooling.png&quot; alt=&quot;image&quot; width=&quot;70%&quot; height=&quot;70%&quot; class=&quot;align-center&quot; /&gt;
&lt;em&gt;Figure 5. Pooling with 2x2 (&lt;a href=&quot;https://fullstackdeeplearning.com/spring2021/lecture-2a/&quot;&gt;source&lt;/a&gt;)&lt;/em&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;dilated-convolution&quot;&gt;&lt;strong&gt;Dilated convolution&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;Dilated convolution은 convolution filter 내 cell 간 간격(dilation)이 벌어진 convolution의 한 종류이다. Convolution filter 내 간격을 정의하는 dilation rate를 하이퍼파라미터로 두게 된다. 구현할 때에는 filter 내의 hole 부분은 0으로 채워 연산을 수행한다. Dialated convolution은 파라미터의 사이즈를 그대로 유지하면서 receptive field를 넓힐 수 있다. 이때, receptive field란 feature를 만들어 내는 input 영역을 말한다. receptive field가 작으면 좋지 않은데, 그 이유는 어떠한 판단을 하는 데 있어 중요한 정보가 고려되지 않을 수 있기 때문이다. 만약 특정 물체의 boundary를 판단하고 싶다고 할 때, receptive field가 물체보다 작다면 물체의 boundary를 명확히 판단할 수 없다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;https://miro.medium.com/max/494/1*SVkgHoFoiMZkjy54zM_SUw.gif&quot; alt=&quot;image&quot; width=&quot;60%&quot; height=&quot;60%&quot; class=&quot;align-center&quot; /&gt;
&lt;em&gt;Figure 6. 2D convolution using with a dilation rate of 2(&lt;a href=&quot;https://towardsdatascience.com/types-of-convolutions-in-deep-learning-717013397f4d&quot;&gt;source&lt;/a&gt;)&lt;/em&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;1x1-convolution&quot;&gt;&lt;strong&gt;1x1 convolution&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;1x1 convolution은 말 그대로 convolution filter의 차원이 1x1인 convolution을 말한다. 이는 보통 channel의 dimension을 줄이기 위해 사용된다. 1x1 convolution을 적용하게 되면 정보를 함축하여 표현하게 되고, 이에 따라 차원이 줄어 연산에 소요되는 시간이 줄어들게 된다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/assets/img/1x1%20convolution.png&quot; alt=&quot;image&quot; width=&quot;70%&quot; height=&quot;70%&quot; class=&quot;align-center&quot; /&gt;
&lt;em&gt;Figure 7. 1x1 convolution example (&lt;a href=&quot;https://fullstackdeeplearning.com/spring2021/lecture-2a/&quot;&gt;source&lt;/a&gt;)&lt;/em&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;classic-convnet-architecture&quot;&gt;&lt;strong&gt;Classic convNet architecture&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;일반적인 CNN 모델은 convolution, non-linear, pooling 순서를 반복하는 feature learning 과정을 가지고 있다. 먼저 convolution 연산을 통해 image에서 feature를 뽑고, 그 다음 relu와 같은 activation funtion을 사용하여 데이터에 non-linearity를 부여한다. 마지막으로 pooling을 통해 차원을 줄이고 output이 translation invariance하게 한다. Feature learning 과정 다음에는 모델의 output을 내기 위한 과정이 존재한다. 이 과정은 task에 dependent한데, image classification의 경우 보통 몇 개의 fully connected layer를 두게 된다. Fully connected layer는 feature learning 과정에서 image에서 얻은 feature를 사용하여 classification을 수행하게 되고, 이미지가 특정 class에 속할 확률을 최종 ouput으로 만들어 낸다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/assets/img/General%20architecture%20cnn.png&quot; alt=&quot;image&quot; width=&quot;80%&quot; height=&quot;70%&quot; class=&quot;align-center&quot; /&gt;
&lt;em&gt;Figure 8. Standard CNN model architecture (&lt;a href=&quot;https://fullstackdeeplearning.com/spring2021/lecture-2a/&quot;&gt;source&lt;/a&gt;)&lt;/em&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;reference&quot;&gt;&lt;strong&gt;Reference&lt;/strong&gt;&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;https://fullstackdeeplearning.com/spring2021/lecture-2a/&lt;/li&gt;
  &lt;li&gt;https://www.youtube.com/watch?v=AjtX1N_VT9E&amp;amp;list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI&amp;amp;index=4&lt;/li&gt;
  &lt;li&gt;https://theaisummer.com/receptive-field/&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Jaeseo Yu</name></author><category term="Deep learning" /><category term="deep learning" /><category term="cnn" /><summary type="html">일반적인 CNN 모델의 구조와 convolution 연산을 비롯하여 CNN 모델을 구성하는 요소에 대해 알아본다.</summary></entry></feed>
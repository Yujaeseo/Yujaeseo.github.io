<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2022-08-07T23:15:43+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Yu’s Tech 블로그</title><subtitle>You will never know until you try.</subtitle><author><name>Jaeseo Yu</name></author><entry><title type="html">NVIDIA GPUDirect storage에 대해</title><link href="http://localhost:4000/hpc/2022/08/07/NVIDIA-GPUDirect-storage/" rel="alternate" type="text/html" title="NVIDIA GPUDirect storage에 대해" /><published>2022-08-07T00:00:00+09:00</published><updated>2022-08-07T00:00:00+09:00</updated><id>http://localhost:4000/hpc/2022/08/07/NVIDIA%20GPUDirect%20storage</id><content type="html" xml:base="http://localhost:4000/hpc/2022/08/07/NVIDIA-GPUDirect-storage/">&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;nvidia-gpudirect&quot;&gt;&lt;strong&gt;NVIDIA GPUDirect&lt;/strong&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;NVIDIA GPUDirect란 NVIDIA data center GPU의 data movement와 access 속도를 높여주는 기술이다. AI를 위해 많은 기업들이 고성능 GPU 서버를 구축하고 있고, 높은 flops를 가지는 GPU의 성능을 활용하기 위해서는 높은 IO bandwidth가 뒷받침되어야 한다. 아래의 이미지는 NVIDIA 기술 세미나에서 인용한 HP의 슬라이드이다. Computer architecture 각 구성 요소들의 처리 속도를 사람의 걸음수로 환산하여 비교한 자료이다. CPU 프로세서의 처리 속도를 한 걸음이라고 했을 때, system memory (DRAM)와 SSD (Flash)의 IO 속도를 각각 100, 200,000 걸음으로 환산할 수 있다. CPU 처리 속도에 비해 주변 장치의 IO 속도가 훨씬 느리기 때문에 processor의 빠른 처리 속도를 십분 활용하기 위해서 IO 속도를 높이는 것이 무엇보다 중요하다고 할 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220807223108967.png&quot; alt=&quot;image-20220807223108967&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;
  &lt;em&gt;Figure 1. Computer architecture (&lt;a href=&quot;https://www.youtube.com/watch?v=ZMf64oB_arY&quot;&gt;source&lt;/a&gt;)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;NIVIDIA GPU의 빠른 처리 속도를 활용해 시스템 성능을 극대화하기 위해 GPUDirect라는 기술을 개발하였고, storage access 최적화를 위한 GPUDirect Storage, network adapter access 최적화를 위한 GPUdirect RDMA, GPU 간 통신 최적화를 위한 GPUDirect P2P를 비롯한 다양한 기술들이 포함되어 있다. 그중 스토리지와의 data movement 속도를 높여주는 NVIDIA GPUDirect Storage(GDS)에 대해 알아보고자 한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;nvidia-gpudirect-storage-gds&quot;&gt;&lt;strong&gt;NVIDIA GPUDirect storage (GDS)&lt;/strong&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;GDS는 local 또는 remote storage(e.g. NVMe or NVMe over Fabric)와 GPU 간 direct path를 이용하여 빠르게 통신할 수 있도록 해주는 기술이다. 이를 통해 IO 시 CPU에서 발생하는 bottleneck을 줄여줄 수 있게된다. GDS가 없을 때는 local 또는 remote storage에서 데이터를 불러올 때 CPU를 거쳐야만 했다. 즉 CPU의 low memory에 있는 bounce buffer에 storage에서 읽은 데이터가 쌓이고, 해당 데이터를 high memory에 copy한 후 해당 데이터가 GPU 메모리로 이동하는 방식이였다. 반면에 GDS를 사용하면 아래의 그림과 같이 CPU를 거치지 않고 storage와 GPU간에 direct하게 통신할 수 있게 된다. GPU와 storage 간의 DMA (Direct Memory Access)를 통해 CPU의 불필요한 memory copy를 줄일 수 있게 되며, 통신을 위해 거치는 data path가 짧아져 data transfer에 소요되는 시간이 줄게된다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/GPUDirect Storage data path.png&quot; alt=&quot;GPUDirect Storage data path&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;
  &lt;em&gt;Fig 2. GPUDirect Storage data path (&lt;a href=&quot;https://nvdam.widen.net/s/k8vrp9xkft/tech-overview-magnum-io-1790750-r5-web&quot;&gt;source&lt;/a&gt;)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;performance&quot;&gt;&lt;strong&gt;Performance&lt;/strong&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;아래의 그래프는 NVIDIA 자체 gdsio benchmarking tool을 이용해서 bandwidth와 cpu utilization을 측정한 자료이다. 자료에 따르면 GDS를 사용하지 않았을 때(CPU-GPU_READ)에 비해 bandwidth는 최대 1.5X 향상되었으며, CPU utilization의 경우 최대 2.8X 향상되었음을 확인할 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/The benefits of using GDS with the gdsio benchmarking tool.png&quot; alt=&quot;The benefits of using GDS with the gdsio benchmarking tool&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;
  &lt;em&gt;Fig 3. The benefits of using GDS with the gdsio benchmarking tool (&lt;a href=&quot;https://nvdam.widen.net/s/k8vrp9xkft/tech-overview-magnum-io-1790750-r5-web&quot;&gt;source&lt;/a&gt;)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Weather pattern을 확인하는 climate simulation deep learning 모델에 GDS, DALI (Nvidia data loading library), deepCAM를 적용하여 inference 성능을 측정했을 때 최대 6.6X의 성능 향상이 있었다. (GDS만 적용했을 때의 성능 개선치만 볼 수 있었다면 좋았을 것 같다).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/Performance benchmarking done for DeepCAM Inference.png&quot; alt=&quot;Performance benchmarking done for DeepCAM Inference&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;
  &lt;em&gt;Fig 4. Performance benchmarking done for DeepCAM Inference using standard GDS configuration in DGX A100 (&lt;a href=&quot;https://nvdam.widen.net/s/k8vrp9xkft/tech-overview-magnum-io-1790750-r5-web&quot;&gt;source&lt;/a&gt;)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;</content><author><name>Jaeseo Yu</name></author><category term="HPC" /><category term="nvidia" /><category term="gpu" /><category term="hpc" /><category term="deep learning" /><category term="machine learning" /><summary type="html">GPU와 storage 간 IO 퍼포먼스를 향상시키는 NVIDIA GPUDirect Storage에 대해 알아본다.</summary></entry><entry><title type="html">Deploying Machine Learning Models in Production_Model Servers-TensorFlow Serving</title><link href="http://localhost:4000/lecture/2022/08/02/Deploying-Machine-Learning-Models-in-Production-Model-Servers-Tensorflow-Serving/" rel="alternate" type="text/html" title="Deploying Machine Learning Models in Production_Model Servers-TensorFlow Serving" /><published>2022-08-02T00:00:00+09:00</published><updated>2022-08-02T00:00:00+09:00</updated><id>http://localhost:4000/lecture/2022/08/02/%5BDeploying%20Machine%20Learning%20Models%20in%20Production%5D%20Model%20Servers-Tensorflow%20Serving</id><content type="html" xml:base="http://localhost:4000/lecture/2022/08/02/Deploying-Machine-Learning-Models-in-Production-Model-Servers-Tensorflow-Serving/">&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;tensorflow-serving1&quot;&gt;&lt;strong&gt;Tensorflow Serving(1)&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220801230627297.png&quot; alt=&quot;image-20220801230627297&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Tensorflow serving은 tensorflow model을 바로 서빙할 수 있으며, Non TF model도 serving이 가능하다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;tensorflow-serving2&quot;&gt;&lt;strong&gt;Tensorflow Serving(2)&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220801230635154.png&quot; alt=&quot;image-20220801230635154&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;다량의 request를 동시에 처리하는 batch inference 기능을 제공한다.
    &lt;ul&gt;
      &lt;li&gt;Recommendation engine에서 주로 사용한다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;단일 request에 대해 빠른 inference 결과를 제공하는 real-time inference 기능도 제공한다.
    &lt;ul&gt;
      &lt;li&gt;Image classification task에서 주로 사용한다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;tensorflow-serving3&quot;&gt;&lt;strong&gt;Tensorflow Serving(3)&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220801230643875.png&quot; alt=&quot;image-20220801230643875&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;동일한 task에대해 여러 모델을 serving하는 것도 가능하다.
    &lt;ul&gt;
      &lt;li&gt;A/B test에 유용하다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;tensorflow-serving4&quot;&gt;&lt;strong&gt;Tensorflow Serving(4)&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220801230657706.png&quot; alt=&quot;image-20220801230657706&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Rest endpoint도 제공한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;tensorflow-serving-architecture1&quot;&gt;&lt;strong&gt;TensorFlow Serving Architecture(1)&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220801230706249.png&quot; alt=&quot;image-20220801230706249&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;High level architecture는 이와 같다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;tensorflow-serving-architecture2&quot;&gt;&lt;strong&gt;TensorFlow Serving Architecture(2)&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220801230714137.png&quot; alt=&quot;image-20220801230714137&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;TF serving은 TF servable을 중심으로 만들어졌으며, TF servable은 추상화된 객체로서 client가 inference나 lookup과 같은 연산을 수행할 때 사용한다.&lt;/li&gt;
  &lt;li&gt;전형적인 servable은 model이나 lookup table이 될수도 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;tensorflow-serving-architecture3&quot;&gt;&lt;strong&gt;TensorFlow Serving Architecture(3)&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220801230722617.png&quot; alt=&quot;image-20220801230722617&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Loader로 TF servable의 lifecycle을 관리한다.&lt;/li&gt;
  &lt;li&gt;Loader API는 일반적인 인프라와 머신러닝 알고리즘, 데이터를 비롯한 태스크와 independent하게 만들어 준다.&lt;/li&gt;
  &lt;li&gt;Loader API로 servable을 load, unload 할수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;tensorflow-serving-architecture4&quot;&gt;&lt;strong&gt;TensorFlow Serving Architecture(4)&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220801230729609.png&quot; alt=&quot;image-20220801230729609&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Source는 loader를 통해 여러 set으로 이루어진 서로 다른 version의 servable이 manager에게 전달한다.&lt;/li&gt;
  &lt;li&gt;새로운 servable이 전달되면 기존의 것은 unload한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;tensorflow-serving-architecture5&quot;&gt;&lt;strong&gt;TensorFlow Serving Architecture(5)&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220801230736712.png&quot; alt=&quot;image-20220801230736712&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;이처럼 manager는 servable의 lifecycle을 통제하며, servable을 loading하거나 list에 없는 servable을 unload할 수 있다.&lt;/li&gt;
  &lt;li&gt;새로운 stream이 들어오면 version policy에 따라 load, unload한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;tensorflow-serving-architecture6&quot;&gt;&lt;strong&gt;TensorFlow Serving Architecture(6)&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220801230744753.png&quot; alt=&quot;image-20220801230744753&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Servable handler는 client가 servable을 이용할 수 있도록 interface를 제공한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;tensorflow-serving-architecture7&quot;&gt;&lt;strong&gt;TensorFlow Serving Architecture(7)&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220801230752000.png&quot; alt=&quot;image-20220801230752000&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;전반적인 프로세스를 이해하기 위해 예시를 들어보자.&lt;/li&gt;
  &lt;li&gt;Source가 빈번하게 weight이 update되는 tensorflow graph라고 가정하자.&lt;/li&gt;
  &lt;li&gt;이러한 weight은 filesystem에 저장이된다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;tensorflow-serving-architecture8&quot;&gt;&lt;strong&gt;TensorFlow Serving Architecture(8)&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220801230759184.png&quot; alt=&quot;image-20220801230759184&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Model의 weight가 바뀌었다고 할때, source는 새로운 버전의 모델을 감지한다.&lt;/li&gt;
  &lt;li&gt;디스크에 있는 모델 데이터의 pointer를 담은 loader를 만든다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;tensorflow-serving-architecture9&quot;&gt;&lt;strong&gt;TensorFlow Serving Architecture(9)&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220801230805817.png&quot; alt=&quot;image-20220801230805817&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Source는 dynamic manager한테 이러한 version을 전달한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;tensorflow-serving-architecture10&quot;&gt;&lt;strong&gt;TensorFlow Serving Architecture(10)&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220801230818129.png&quot; alt=&quot;image-20220801230818129&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Dynamic manger는 version policy에 따라 새로운 version을 load한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;tensorflow-serving-architecture11&quot;&gt;&lt;strong&gt;TensorFlow Serving Architecture(11)&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220801230830401.png&quot; alt=&quot;image-20220801230830401&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;메모리가 충분하면, loader는 manager의 요청에의해 변경된 weight이 반영된 tensorflow graph를 servable로 instance화한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;tensorflow-serving-architecture12&quot;&gt;&lt;strong&gt;TensorFlow Serving Architecture(12)&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220801230838113.png&quot; alt=&quot;image-20220801230838113&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Client는 새로운 버전에 대한 handle을 요청하면 manager는 servable에 대한 handle을 return한다.&lt;/li&gt;
  &lt;li&gt;Client는 해당 servable을 이용하여 inference를 수행한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;-참고자료&quot;&gt;&lt;strong&gt;# 참고자료&lt;/strong&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;아키텍처 전반과 용어에 대한 설명이 적혀있는 참고자료
    &lt;ul&gt;
      &lt;li&gt;https://github.com/tensorflow/serving/blob/master/tensorflow_serving/g3doc/architecture.md&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>Jaeseo Yu</name></author><category term="Lecture" /><category term="mlops" /><category term="deep learning" /><category term="machine learning" /><category term="lecture summary" /><summary type="html">Model server 중 하나인 tensorflow serving에 대한 아키텍처를 살펴본다.</summary></entry><entry><title type="html">Deploying Machine Learning Models in Production_Installing TensorFlow Serving</title><link href="http://localhost:4000/lecture/2022/07/31/Deploying-Machine-Learning-Models-in-Production-Installing-tensorflow-serving/" rel="alternate" type="text/html" title="Deploying Machine Learning Models in Production_Installing TensorFlow Serving" /><published>2022-07-31T00:00:00+09:00</published><updated>2022-07-31T00:00:00+09:00</updated><id>http://localhost:4000/lecture/2022/07/31/%5BDeploying%20Machine%20Learning%20Models%20in%20Production%5D%20Installing%20tensorflow%20serving</id><content type="html" xml:base="http://localhost:4000/lecture/2022/07/31/Deploying-Machine-Learning-Models-in-Production-Installing-tensorflow-serving/">&lt;hr /&gt;

&lt;h2 id=&quot;install-tensorflow-serving-1&quot;&gt;&lt;strong&gt;Install Tensorflow Serving (1)&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731110109225.png&quot; alt=&quot;image-20220731110109225&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Tensorflow serving을 설치하는 가장 쉬운 방법은 docker image를 사용하는 것이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;install-tensorflow-serving-2&quot;&gt;&lt;strong&gt;Install Tensorflow Serving (2)&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731110124591.png&quot; alt=&quot;image-20220731110124591&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Binaries를 이용해서 직접 다운로드 받는 방법은 다음과 같다.&lt;/li&gt;
  &lt;li&gt;Tensorflow-model-server는 플랫폼에 종속된 optimization 방식이 적용된 반면,&lt;/li&gt;
  &lt;li&gt;Tensorflow-model-server-universal은 플랫폼에 종속된 optimization 방식이 적용되지 않았다는 점이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;install-tensorflow-serving-3&quot;&gt;&lt;strong&gt;Install Tensorflow Serving (3)&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731110132863.png&quot; alt=&quot;image-20220731110132863&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;직접 customize를 하길 원한다면 source로도 build를 할 수 있다.&lt;/p&gt;

    &lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;install-tensorflow-serving-4&quot;&gt;&lt;strong&gt;Install Tensorflow Serving (4)&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731110141743.png&quot; alt=&quot;image-20220731110141743&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Tensorflow serving을 다운로드 받을 수 있는 archive 위치 정보를 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/etc/apt/sources.list.d&lt;/code&gt;에 등록한다.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;인증을 위한 key를 불러오고, apt 업데이트 후 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;apt-get&lt;/code&gt;을 이용하여 tensorflow serving을 다운받는다.&lt;/p&gt;

    &lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;import-the-mnist-dataset&quot;&gt;&lt;strong&gt;Import the MNIST Dataset&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731110150647.png&quot; alt=&quot;image-20220731110150647&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;MNIST 데이터셋을 이용하여 비전 모델을 학습시킨다.
    &lt;ul&gt;
      &lt;li&gt;70,000장 (train 60,000/ test 10,000)의 0-9 grayscale 이미지(28x28)로 이루어져있다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Numpy array 형식으로 데이터를 불러오고 0-1 scale 값으로 normalization을 수행한다.&lt;/p&gt;

    &lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;import-the-mnist-dataset-1&quot;&gt;&lt;strong&gt;Import the MNIST Dataset&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731110209791.png&quot; alt=&quot;image-20220731110209791&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Train, test 각각을 (60,000 x 28 x 28 x 1), (10,000 x 28 x 28 x 1) 형식의 array로 변환한다.&lt;/p&gt;

    &lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;look-at-a-sample-image&quot;&gt;&lt;strong&gt;Look at a Sample Image&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731110217800.png&quot; alt=&quot;image-20220731110217800&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Sample image를 확인한다.&lt;/p&gt;

    &lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;build-a-model&quot;&gt;&lt;strong&gt;Build a Model&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731110226735.png&quot; alt=&quot;image-20220731110226735&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;간단한 CNN 모델을 구성한다.&lt;/p&gt;

    &lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;train-the-model&quot;&gt;&lt;strong&gt;Train the Model&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731110234568.png&quot; alt=&quot;image-20220731110234568&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;모델 training에 사용할 optimizer, loss, metric을 세팅한다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Fit&lt;/code&gt;을 실행하면 모델 학습이 진행되고, history 변수에는 epoch by epoch accuracy가 저장된다.&lt;/p&gt;

    &lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;evaluate-the-model&quot;&gt;&lt;strong&gt;Evaluate the Model&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731110241758.png&quot; alt=&quot;image-20220731110241758&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Testset에 대해 학습된 모델의 정확도를 평가한다.
&lt;br /&gt;&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;save-the-model&quot;&gt;&lt;strong&gt;Save the Model&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731110250111.png&quot; alt=&quot;image-20220731110250111&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Tensorflow serving을 사용하기 위해서는 모델을 저장해야한다.&lt;/p&gt;

    &lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;launch-your-saved-model&quot;&gt;&lt;strong&gt;Launch Your Saved Model&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731110257655.png&quot; alt=&quot;image-20220731110257655&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;bash script로 tensorflow model server를 세팅해준다. (port, 모델 이름, 모델 path)&lt;/p&gt;

    &lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;send-an-inference-request&quot;&gt;&lt;strong&gt;Send an Inference Request&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731110306735.png&quot; alt=&quot;image-20220731110306735&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Test set에 속하는 몇개의 이미지를 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;json&lt;/code&gt; 형식으로 변환한후 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;POST&lt;/code&gt;로 서버에 request를 보낸다.&lt;/p&gt;

    &lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;plot-predictions&quot;&gt;&lt;strong&gt;Plot Predictions&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731110314567.png&quot; alt=&quot;image-20220731110314567&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;결과를 시각화하는 코드를 작성한다.&lt;/p&gt;

    &lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;results-demo&quot;&gt;&lt;strong&gt;Results Demo&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731110323919.png&quot; alt=&quot;image-20220731110323919&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;결과가 정확하게 나온 것을 확인할 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;</content><author><name>Jaeseo Yu</name></author><category term="Lecture" /><category term="mlops" /><category term="deep learning" /><category term="machine learning" /><category term="lecture summary" /><summary type="html">Google colab을 이용하여 tensorflow serving을 install하고 간단한 CNN 모델을 통해 실습을 진행한다.</summary></entry><entry><title type="html">Deploying Machine Learning Models in Production_Model Serving Architecture</title><link href="http://localhost:4000/lecture/2022/07/31/Deploying-Machine-Learning-Models-in-Production-Model-Serving-Architecture/" rel="alternate" type="text/html" title="Deploying Machine Learning Models in Production_Model Serving Architecture" /><published>2022-07-31T00:00:00+09:00</published><updated>2022-07-31T00:00:00+09:00</updated><id>http://localhost:4000/lecture/2022/07/31/%5BDeploying%20Machine%20Learning%20Models%20in%20Production%5D%20Model%20Serving%20Architecture</id><content type="html" xml:base="http://localhost:4000/lecture/2022/07/31/Deploying-Machine-Learning-Models-in-Production-Model-Serving-Architecture/">&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;ml-infrastructure-1&quot;&gt;&lt;strong&gt;ML Infrastructure (1)&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731165510452.png&quot; alt=&quot;image-20220731165510452&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Model serving을 위한 infrastructure에 대해 알아볼 것이다.&lt;/li&gt;
  &lt;li&gt;크게 자체 구축한 on-premise 환경 또는 cloud 서비스를 이용하는 두가지 방법이 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;ml-infrastructure_on-premise-2&quot;&gt;&lt;strong&gt;ML Infrastructure_On-Premise (2)&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731165518094.png&quot; alt=&quot;image-20220731165518094&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;On-Premise는 소유한 회사가 하드웨어와 소프트웨어에 대한 전적인 통제 권한을 가질 수 있다.&lt;/li&gt;
  &lt;li&gt;따라서, 시시각각 변하는 다양한 요구 조건에 빠르게 대처할 수 있다는 장점이 존재한다.&lt;/li&gt;
  &lt;li&gt;하지만 하드웨어 인프라를 직접 구하고, 설치하고, 유지보수해야한다는 점에서 큰 비용이 생긴다.&lt;/li&gt;
  &lt;li&gt;일반적으로 규모의 경제를 실현할 수 있는 큰 규모의 회사들이 on-premise 환경을 구축하고 운영한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;ml-infrastructure_cloud-3&quot;&gt;&lt;strong&gt;ML Infrastructure_Cloud (3)&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731165526447.png&quot; alt=&quot;image-20220731165526447&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;규모가 작은 기업들은 이러한 인프라를 전문 기업에게 outsourcing 하는 방법이 있다.&lt;/li&gt;
  &lt;li&gt;아마존, 구글, 마이크로소프트와 같은 기업들이 cloud 서비스를 제공한다.&lt;/li&gt;
  &lt;li&gt;하드웨어를 직접 구축할 필요가 없고 해당 기업들이 하드웨어, 소프트웨어 전반을 관리 및 모니터링해준다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;model-serving-1&quot;&gt;&lt;strong&gt;Model Serving (1)&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731165534694.png&quot; alt=&quot;image-20220731165534694&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;인프라 선택뿐만 아니라 model serving 방법 또한 선택해야한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;model-serving_on-premise-2&quot;&gt;&lt;strong&gt;Model Serving_On-Premise (2)&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731165542350.png&quot; alt=&quot;image-20220731165542350&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;On-premise에서는 원하는 model server를 선택하고 구축할 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;model-serving_cloud3&quot;&gt;&lt;strong&gt;Model Serving_Cloud(3)&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731165549647.png&quot; alt=&quot;image-20220731165549647&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Cloud를 사용하는 경우 cloud vendor에서 제공하는 tool과 service를 사용할 수 있다.
    &lt;ul&gt;
      &lt;li&gt;Google의 경우 automl을 비롯한 다양한 서비스를, amazon의 경우 sagemaker와 같은 서비스를 사용할 수 있다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;아니면 cloud에 VM을 활용하여 on-premise와 동일하게 직접 원하는 환경과 서비스를 구축할수도 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;model-servers-1&quot;&gt;&lt;strong&gt;Model Servers (1)&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731165556703.png&quot; alt=&quot;image-20220731165556703&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Model server의 역할을 간단하게 알아보자.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;model-servers_model-file2&quot;&gt;&lt;strong&gt;Model Servers_Model file(2)&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731165604454.png&quot; alt=&quot;image-20220731165604454&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;모델은 여러 버전으로 file system에 저장이 된다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;model-servers_model-server3&quot;&gt;&lt;strong&gt;Model Servers_Model server(3)&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731165612567.png&quot; alt=&quot;image-20220731165612567&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Model server는 model을 file에서 읽고 인스턴스로 생성하여, client에게 제공하길 원하는 task에 대한 response를 한다.&lt;/li&gt;
  &lt;li&gt;예를들어 Mobilenet을 이용한 classification을 수행한다고 했을 때, 모델 서버는 input으로 주어진 이미지를 tensor 형태로 변형하고 이를 model에 전달하여 inference 결과를 산출한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;model-servers_api4&quot;&gt;&lt;strong&gt;Model Servers_API(4)&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731165624486.png&quot; alt=&quot;image-20220731165624486&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Model server는 client에게 REST 또는 gRPC 형태의 API를 제공하고 inference 결과를 client에게 return한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;model-servers_popular-model-server5&quot;&gt;&lt;strong&gt;Model Servers_Popular model server(5)&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220731165635639.png&quot; alt=&quot;image-20220731165635639&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;유명한 model server에는 Tensorflow serving, Torchserve, KF serving, Triton이 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;</content><author><name>Jaeseo Yu</name></author><category term="Lecture" /><category term="mlops" /><category term="deep learning" /><category term="machine learning" /><category term="lecture summary" /><summary type="html">Model serving에 필요한 infrastructure의 종류와 model server에 대해 알아본다.</summary></entry><entry><title type="html">Deploying Machine Learning Models in Production_Deployment Options</title><link href="http://localhost:4000/lecture/2022/07/30/Deploying-Machine-Learning-Models-in-Production-Deployment-Options/" rel="alternate" type="text/html" title="Deploying Machine Learning Models in Production_Deployment Options" /><published>2022-07-30T00:00:00+09:00</published><updated>2022-07-30T00:00:00+09:00</updated><id>http://localhost:4000/lecture/2022/07/30/%5BDeploying%20Machine%20Learning%20Models%20in%20Production%5D%20Deployment%20Options</id><content type="html" xml:base="http://localhost:4000/lecture/2022/07/30/Deploying-Machine-Learning-Models-in-Production-Deployment-Options/">&lt;hr /&gt;

&lt;h2 id=&quot;model-deployments&quot;&gt;&lt;strong&gt;Model Deployments&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220730095805422.png&quot; alt=&quot;image-20220730095805422&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;모델 배포는 데이터센터와 같이 대규모의 인프라 공간에 모델을 중앙집중형 서버에 배포하는 것과 각 사용자의 local device에 배포하는 두가지가 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;running-in-huge-data-centers&quot;&gt;&lt;strong&gt;Running in Huge Data Centers&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220730095619218.png&quot; alt=&quot;image-20220730095619218&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;데이터센터를 운영하면 cost를 줄이기 위한 노력을 수행한다.
    &lt;ul&gt;
      &lt;li&gt;Google과 같은 큰 기업들은 지속적으로 데이터센터의 resource utilization, application의 cost를 줄이려고 한다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;constrained-environment-mobile-phone&quot;&gt;&lt;strong&gt;Constrained Environment: Mobile Phone&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220730095627775.png&quot; alt=&quot;image-20220730095627775&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;거대한 데이터센터 뿐만 아니라 핸드폰과 같은 제한된 모바일 환경에서도 모델을 serving하기도 한다.&lt;/li&gt;
  &lt;li&gt;모바일핸드폰의 GPU에는 데이터센터에서 사용되는 GPU보다 크기가 훨씬 작고 메모리 용량은 일반적으로 4GB가 넘지 않는다.&lt;/li&gt;
  &lt;li&gt;이러한 GPU를 우리가 배포한 application이 점유하는 것이 아니라 실행되고 있는 여러 application이 점유하게 된다.&lt;/li&gt;
  &lt;li&gt;또한 GPU를 이용하여 연산을 가속화하면 배터리가 빨리 닳게 되고 열이 발생해 application에 대한 인식이 좋지 않아질 것이다.&lt;/li&gt;
  &lt;li&gt;마지막으로, application의 용량이 커지면 다운로드 받기 꺼려질 것이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;restrictions-in-a-constrained-environment&quot;&gt;&lt;strong&gt;Restrictions in a Constrained Environment&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220730095635328.png&quot; alt=&quot;image-20220730095635328&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;낮은 메모리 용량, 프로세싱 파워, 배터리 용량과 같은 제한된 요건을 갖기 때문에 edge device에 큰 모델을 배포할 수 없다.&lt;/li&gt;
  &lt;li&gt;이러한 이유로 보통 서버에 모델을 배포하고 REST API를 통해 서비스를 하지만, latency가 매우 중요할 때는  적합하지 않다.
    &lt;ul&gt;
      &lt;li&gt;자율주행자동차는 실시간으로 그때그때 판단을 해야 하는데, 서버와 통신을 하게 되면 network 지연과 같은 문제로 큰 문제가 초래될 수 있다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;prediction-latency-is-almost-always-important&quot;&gt;&lt;strong&gt;Prediction Latency is Almost Always Important&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220730095647690.png&quot; alt=&quot;image-20220730095647690&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;항상 latency 를 줄여 application의 response time을 줄여 user experience를 향상시켜라.
    &lt;ul&gt;
      &lt;li&gt;예외적인 경우는 prediction의 정확도가 훨씬 중요한 task를 수행할 때이다.&lt;/li&gt;
      &lt;li&gt;예시는 질병 분석이 있다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;이때 model complexity, size와 같은 trade-off 관계에 있는 요소들도 고려해야 하며, 발생하는 cost도 고려해야 한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;choose-best-model-for-the-task&quot;&gt;&lt;strong&gt;Choose Best Model for the Task&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220730095656008.png&quot; alt=&quot;image-20220730095656008&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;언급한 constraints를 기준으로 최적의 모델을 선택해야한다.
    &lt;ul&gt;
      &lt;li&gt;Mobilenet은 모바일 환경을 위해 개발된 모델이다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;other-strategies&quot;&gt;&lt;strong&gt;Other Strategies&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220730095702751.png&quot; alt=&quot;image-20220730095702751&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;프로파일링을 통해 병목지점을 파악하고,&lt;/li&gt;
  &lt;li&gt;특정 operation이 많은 시간을 차지한다는 것을 발견한다면, 해당 부분은 최적화해야 한다.&lt;/li&gt;
  &lt;li&gt;모델 자체를 최적화하여 더 빠르고 energy efficient한 모델을 만들수도 있며 특히 mobile 환경에서 중요하다.&lt;/li&gt;
  &lt;li&gt;사용하는 thread의 수를 늘리는 방법도 있다.
    &lt;ul&gt;
      &lt;li&gt;하지만 thread 수를 늘린다고 해서 무조건 성능이 좋아지는 것은 아니다.&lt;/li&gt;
      &lt;li&gt;무엇을 concurrent하게 실행하고 있는지 등에 따라 성능 차이가 발생한다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;web-applications-for-users&quot;&gt;&lt;strong&gt;Web Applications for Users&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220730095709919.png&quot; alt=&quot;image-20220730095709919&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;모델에서 서비스를 받는 유저는 request를 web application을 통해한다.&lt;/li&gt;
  &lt;li&gt;Model은 API 서비스 형태로 존재하고, 이러한 과정을 돕는 다양한 web framework들이 존재한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;serving-systems-for-easy-deployment&quot;&gt;&lt;strong&gt;Serving systems for easy deployment&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220730095716511.png&quot; alt=&quot;image-20220730095716511&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;모델 서빙 시스템은 다양한 방식으로 모델 배포를 관리한다.
    &lt;ul&gt;
      &lt;li&gt;서버에 모델을 배포하여 서비스를 제공할 수 있으며,&lt;/li&gt;
      &lt;li&gt;Custom website가 필요하지 않고,&lt;/li&gt;
      &lt;li&gt;몇줄 안되는 코드로 배포가 가능하고,&lt;/li&gt;
      &lt;li&gt;Model update와 rollback을 편리하게 수행할 수 있다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;clipper&quot;&gt;&lt;strong&gt;Clipper&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220730095723575.png&quot; alt=&quot;image-20220730095723575&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Clipper는 UC berkely에서 만든 model serving 시스템이다.
    &lt;ul&gt;
      &lt;li&gt;다양한 모델 배포를 지원하며, restful API로 기존 application과 쉽게 통합할 수 있으며, 도커로 컨테이너화하여 자원 관리를 지원하며, latency setting을 할 수 있다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;tensorflow-serving&quot;&gt;&lt;strong&gt;TensorFlow Serving&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220730095732320.png&quot; alt=&quot;image-20220730095732320&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Tensorflow serving은 구글에서 만든 오픈소스이다.
    &lt;ul&gt;
      &lt;li&gt;텐서플로우 모델을 쉽게 배포할 수 있으며,&lt;/li&gt;
      &lt;li&gt;다른 타입의 모델도 배포할 수 있으며,&lt;/li&gt;
      &lt;li&gt;REST와 gRPC 프로토콜을 제공하며,&lt;/li&gt;
      &lt;li&gt;모델의 version management가 가능하다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;advantages-of-serving-with-a-managed-service&quot;&gt;&lt;strong&gt;Advantages of Serving with a Managed Service&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220730095739374.png&quot; alt=&quot;image-20220730095739374&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Google cloud와 같은 managed service를 사용하면 더 편할 수 있다.
    &lt;ul&gt;
      &lt;li&gt;낮은 latency의 endpoint를 제공하고 대량의 batch를 처리할 수 있으며,&lt;/li&gt;
      &lt;li&gt;별도 환경 또는 클라우드에서 학습한 모델을 배포할 수 있으며,&lt;/li&gt;
      &lt;li&gt;traffic에 기반하여 자동으로 scaling을 수행하고&lt;/li&gt;
      &lt;li&gt;GPU/TPU와 같은 연산 가속기도 지원한다.
        &lt;ul&gt;
          &lt;li&gt;Google 외에도 MS, Amazon과 같은 기업들이 비슷한 서비스를 제공한다.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;</content><author><name>Jaeseo Yu</name></author><category term="Lecture" /><category term="mlops" /><category term="deep learning" /><category term="machine learning" /><category term="lecture summary" /><summary type="html">Model serving을 위한 다양한 option들에 대해 알아본다.</summary></entry><entry><title type="html">Deploying Machine Learning Models in Production_Introduction to Model Serving Infrastructure</title><link href="http://localhost:4000/lecture/2022/07/29/Deploying-Machine-Learning-Models-in-Production-Introduction-to-Model-Serving-Infrastructure/" rel="alternate" type="text/html" title="Deploying Machine Learning Models in Production_Introduction to Model Serving Infrastructure" /><published>2022-07-29T00:00:00+09:00</published><updated>2022-07-29T00:00:00+09:00</updated><id>http://localhost:4000/lecture/2022/07/29/%5BDeploying%20Machine%20Learning%20Models%20in%20Production%5D%20Introduction%20to%20Model%20Serving%20Infrastructure</id><content type="html" xml:base="http://localhost:4000/lecture/2022/07/29/Deploying-Machine-Learning-Models-in-Production-Introduction-to-Model-Serving-Infrastructure/">&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;optimizing-models-for-serving&quot;&gt;&lt;strong&gt;Optimizing Models for Serving&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220729225850339.png&quot; alt=&quot;image-20220729225850339&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;최근 모델의 정확도를 높이기 위해 model에 feature 수를 늘리는 등 모델 자체의 complexity가 커지고 있다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;정확도는 높아지지만 이로인해 prediction latency도 커지고 있다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;as-model-complexity-increases-cost-increases&quot;&gt;&lt;strong&gt;As Model Complexity Increases Cost Increases&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220729225858482.png&quot; alt=&quot;image-20220729225858482&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;모델 complexity의 증가는 비용을 초래한다.&lt;/li&gt;
  &lt;li&gt;GPU, TPU와 같은 하드웨어와 model registry, maintenance에 있어서의 비용이 포함된다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;balancing-cost-and-complexity&quot;&gt;&lt;strong&gt;Balancing Cost and Complexity&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220729225907449.png&quot; alt=&quot;image-20220729225907449&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;모델의 정확도와 prediction 속도 간에는 trade-off 관계가 존재하며, 이 사이의 균형을 맞추는 것이 중요하다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;optimizing-and-satisficing-metrics&quot;&gt;&lt;strong&gt;Optimizing and Satisficing Metrics&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220729225915162.png&quot; alt=&quot;image-20220729225915162&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;모델의 정확도를 측정하는 metric으로 accuracy, precision, recall이 있다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;반면, 연산상의 제약 조건과 관련된 metric으로는 latency, model size, GPU load가 있다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;optimizing-and-satisficing-metrics-1&quot;&gt;&lt;strong&gt;Optimizing and Satisficing Metrics&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220729225927745.png&quot; alt=&quot;image-20220729225927745&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;이와 같은 metric을 만족하는 방법은 우선 특정한 serving infrastructure에서 model의 complexity를 증가시키는 것이다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Latency와 같은 연산 상의 제약조건 metric threshold에(e.g. latency) 걸리는 순간까지 정확도를 높인다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;이후 최종 결과를 평가하고 난 후에 정확도를 높이거나, infra를 증축하거나, 모델의 complexity를 줄이거나와 같은 대책을 마련하고 실행한다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;use-of-accelerators-in-serving-infrastructure&quot;&gt;&lt;strong&gt;Use of Accelerators in Serving Infrastructure&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220729225935034.png&quot; alt=&quot;image-20220729225935034&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Accelerator를 통해 infrastructure를 최적화할 수 있다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;GPU의 경우는 training 가속화에 강점을 보이며,&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;TPU는 large batch size, complex model inference에 강점이 있다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;maintaining-input-feature-lookup&quot;&gt;&lt;strong&gt;Maintaining Input Feature Lookup&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220729225942225.png&quot; alt=&quot;image-20220729225942225&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Prediction을 수행할 때에는 많은 feature들이 필요할 수 있다.&lt;/li&gt;
  &lt;li&gt;예를들어 음식 배달 시간을 예측한다고 할때, 주문 수, 현재 교통 상황, 처리되지 않은 주문 수와 같은 많은 정보들이 필요하다.&lt;/li&gt;
  &lt;li&gt;Prediction latency를 줄이기 위해서는 사용되는 대량의 정보를 data store에서 빠르게 읽을 수 있어야 한다.&lt;/li&gt;
  &lt;li&gt;이때 cache를 사용하면 필요한 정보를 빠르게 읽어 latency를 낮출 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;nosql-databases-caching-and-feature-lookup&quot;&gt;&lt;strong&gt;NoSQL Databases: Caching and Feature Lookup&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction to Model Serving/Introduction to Model Serving Infrastructure/image-20220729225950122.png&quot; alt=&quot;image-20220729225950122&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;NoSQL은 caching과 feature look up을 구현하기에 좋으며, 위와 같이 다양한 옵션들이 존재한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;</content><author><name>Jaeseo Yu</name></author><category term="Lecture" /><category term="mlops" /><category term="deep learning" /><category term="machine learning" /><category term="lecture summary" /><summary type="html">Model serving 인프라에서 고려해야할 점들에 대한 내용을 알아본다.</summary></entry><entry><title type="html">Deploying Machine Learning Models in Production_Introduction to Model Serving</title><link href="http://localhost:4000/lecture/2022/07/28/Deploying-Machine-Learning-Models-in-Production-Introduction-to-Model-Serving/" rel="alternate" type="text/html" title="Deploying Machine Learning Models in Production_Introduction to Model Serving" /><published>2022-07-28T00:00:00+09:00</published><updated>2022-07-28T00:00:00+09:00</updated><id>http://localhost:4000/lecture/2022/07/28/%5BDeploying%20Machine%20Learning%20Models%20in%20Production%5D%20Introduction%20to%20Model%20Serving</id><content type="html" xml:base="http://localhost:4000/lecture/2022/07/28/Deploying-Machine-Learning-Models-in-Production-Introduction-to-Model-Serving/">&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;what-exactly-is-serving-a-model&quot;&gt;&lt;strong&gt;What exactly is Serving a Model?&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction%20to%20Model%20Serving/what%20exactly%20is%20Serving%20a%20Model.png&quot; alt=&quot;image&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;전체 ML 프로젝트에서 model training은 우리가 아는 굉장히 일부분이다.&lt;/li&gt;
  &lt;li&gt;그중 model serving은 학습시킨 model을 end user가 사용할 수 있도록 하는 것이며,&lt;/li&gt;
  &lt;li&gt;이를 위해서는 end user가 interaction할 수 있는 app 또는 서비스가 필요하다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;model-serving-patterns&quot;&gt;&lt;strong&gt;Model Serving patterns&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction%20to%20Model%20Serving/Model%20Serving%20patterns.png&quot; alt=&quot;image&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Inference는 모델에 입력 값을 넣고 예측을 하는 과정이며,&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;크게 세가지 (model, interpreter, input data)가 필요하다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;ml-workflows&quot;&gt;&lt;strong&gt;ML workflows&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction%20to%20Model%20Serving/ML%20workflows.png&quot; alt=&quot;image&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;ML workflow는 크게 &lt;strong&gt;model training&lt;/strong&gt;, &lt;strong&gt;model prediction&lt;/strong&gt; 두 가지로 나뉜다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;이때, model training은 &lt;strong&gt;offline learning(batch learning, static learning)&lt;/strong&gt;과 &lt;strong&gt;online learning(dynamic learning)&lt;/strong&gt;으로 나눌 수 있다.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Offline learning&lt;/strong&gt;
        &lt;ul&gt;
          &lt;li&gt;Offline learning은 일정 기간 동안 이미 수집된 데이터를 바탕으로 특정 시기에 모델 학습을 시키는 것이다.&lt;/li&gt;
          &lt;li&gt;즉 기존 data와 새로 들어온 data를 함께 학습시키게 되며 대량의 데이터를 한번에 처리하기 때문에 학습시 많은 시간과 자원이 소요된다.&lt;/li&gt;
          &lt;li&gt;모델을 배포하면 재학습시까지 모델은 고정된 상태가 되며, 오랜 시간이 지나면 새로운 pattern에 대응하지 못하며 &lt;strong&gt;model decay&lt;/strong&gt;가 발생한다.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Online learning&lt;/strong&gt;
        &lt;ul&gt;
          &lt;li&gt;Online learning 은 실시간으로 스트림 데이터가 들어올 때 마다 주기적으로 모델을 학습시키는 것이다.&lt;/li&gt;
          &lt;li&gt;주로 sensor, stock 데이터와 같은 time-series data을 토대로 학습을 할때 많이 활용한다.
&lt;br /&gt;&lt;br /&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Model prediction도 &lt;strong&gt;Batch prediction, Realtime prediction&lt;/strong&gt; 두 타입이 존재한다.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Batch prediction&lt;/strong&gt;
        &lt;ul&gt;
          &lt;li&gt;Batch prediction은 과거에 모인 다량의 데이터를 기반으로 예측을 하는것이다.&lt;/li&gt;
          &lt;li&gt;즉 한번의 예측에서 많은 수의 인스턴스를 처리하게 된다.&lt;/li&gt;
          &lt;li&gt;데이터가 time dependent하지 않고, realtime으로 예측을 하는 것이 중요하지 않은 상황에 적절하다.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Realtime prediction&lt;/strong&gt;
        &lt;ul&gt;
          &lt;li&gt;Real time prediction은 inference 요청이 온 시점에 들어온 데이터를 기반으로 실시간으로 prediction을 하는 것이다.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;important-metrics&quot;&gt;&lt;strong&gt;Important metrics&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction%20to%20Model%20Serving/Important%20metrics.png&quot; alt=&quot;image&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Online inference에서 중요하게 살펴보는 metric으로는 latency, throughput, cost가 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;lantency&quot;&gt;&lt;strong&gt;Lantency&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction%20to%20Model%20Serving/Lantency.png&quot; alt=&quot;image&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Latency는 user의 요청과 이에대한 application의 응답까지의 시간을 의미한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;throughput&quot;&gt;&lt;strong&gt;Throughput&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction%20to%20Model%20Serving/Throughput.png&quot; alt=&quot;image&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Throughput은 단위 시간동안 처리한 요청의 수를 의미한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;cost&quot;&gt;&lt;strong&gt;Cost&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction%20to%20Model%20Serving/Cost.png&quot; alt=&quot;image&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Serving infrastructure는 반드시 cost를 수반하게 된다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;minimizing-latency-maximizing-throughput&quot;&gt;&lt;strong&gt;Minimizing Latency, Maximizing Throughput&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction%20to%20Model%20Serving/Minimizing%20Latency,%20Maximizing%20Throughput.png&quot; alt=&quot;image&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;많은 기업들은 latency를 최소화하며, throughput을 최대화하길 원한다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;예를들어 항공사 추천 서비스가 있다고 할때, 유저의 요청에 빠르게 응답할 수 있어야하며, 공휴일과 같이 유저가 몰리는 시간에는 많은 요청을 빠르게 처리할 수 있어야 한다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;이러한 요건을 충족시키기 위해서는 infrastructure를 확장해야 하는데, 이때 큰 비용이 발생한다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;balance-cost-latency-and-throughput&quot;&gt;&lt;strong&gt;Balance Cost, Latency and Throughput&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Lecture/Introduction%20to%20Model%20Serving/Balance%20Cost,%20Latency%20and%20Throughput.png&quot; alt=&quot;image&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Infrastructure 확장에 많은 비용을 투자하지 않고 이러한 비용을 낮추기 위한 방법이 있다.
    &lt;ul&gt;
      &lt;li&gt;GPU 자원 공유&lt;/li&gt;
      &lt;li&gt;Multi model serving&lt;/li&gt;
      &lt;li&gt;Model optimization&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>Jaeseo Yu</name></author><category term="Lecture" /><category term="mlops" /><category term="deep learning" /><category term="machine learning" /><category term="lecture summary" /><summary type="html">Model serving이란 무엇이며, 중요하게 고려해야할 metric에 대해 알아본다.</summary></entry><entry><title type="html">Multithreading vs. Multiprocessing</title><link href="http://localhost:4000/operating%20system/2021/09/19/Multiprocess&multithread/" rel="alternate" type="text/html" title="Multithreading vs. Multiprocessing" /><published>2021-09-19T00:00:00+09:00</published><updated>2021-09-19T00:00:00+09:00</updated><id>http://localhost:4000/operating%20system/2021/09/19/%20Multiprocess&amp;multithread</id><content type="html" xml:base="http://localhost:4000/operating%20system/2021/09/19/Multiprocess&amp;multithread/">&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;process&quot;&gt;&lt;strong&gt;Process&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;프로세스는 실행중인 프로그램이다.&lt;/strong&gt; 즉 프로그램 자체는 프로세스가 아니라, 프로그램이 메모리에 올라가서 실행중일 때 프로세스가 되는 것이다. 프로세스는 크게 5가지 영역(text, stack, data, heap, program counter)로 나눌 수 있다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Text : Program code&lt;/li&gt;
  &lt;li&gt;Stack : Temporary data (function parameter, return addresses, local variables, etc)&lt;/li&gt;
  &lt;li&gt;Data : Static &amp;amp; global variables&lt;/li&gt;
  &lt;li&gt;Heap : Dynamic allocation&lt;/li&gt;
  &lt;li&gt;Program counter &amp;amp; registers : Current activity&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;https://www.tutorialspoint.com/operating_system/images/process_components.jpg&quot; alt=&quot;image&quot; width=&quot;45%&quot; height=&quot;45%&quot; class=&quot;align-center&quot; /&gt;
&lt;em&gt;Figure 1. Process in memory (&lt;a href=&quot;https://www.tutorialspoint.com/operating_system/os_processes.htm&quot;&gt;source&lt;/a&gt;)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;thread&quot;&gt;&lt;strong&gt;Thread&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Thread는 프로세스 내에서 실행되는 단위를 말한다.&lt;/strong&gt; 일반적으로 한 프로세스는 하나의 스레드를 가지고 있지만, 프로그램 환경에 따라 둘 이상의 thread를 동시에 실행시킬 수 있다. 각 Thread는 program counter, register set, stack space를 별도로 지니고 있다. 반면, 각 thread는 프로세스 내 code, data, heap, file과 같은 operating system 자원을 공유하게 된다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;https://www.tutorialspoint.com/operating_system/images/thread_processes.jpg&quot; alt=&quot;image&quot; width=&quot;90%&quot; height=&quot;90%&quot; class=&quot;align-center&quot; /&gt;
&lt;em&gt;Figure 2. Single thread vs Multithreads (&lt;a href=&quot;https://www.tutorialspoint.com/operating_system/os_multi_threading.htm&quot;&gt;source&lt;/a&gt;)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;multithreading-multiprocessing-비교&quot;&gt;&lt;strong&gt;Multithreading, multiprocessing 비교&lt;/strong&gt;&lt;/h2&gt;
&lt;h3 id=&quot;multithreading--장점&quot;&gt;&lt;strong&gt;Multithreading : 장점&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Thread 간 Resource sharing이 가능하다.
    &lt;ul&gt;
      &lt;li&gt;동일 프로세스 내 thread 간 데이터를 공유할 수 있다. 만약 subset으로 나누기 어려운 대량의 데이터를 다뤄야 할 경우, 데이터를 복사하거나 shared memory 방식을 사용해서 프로세스 간 데이터를 전송 또는 공유해야 한다. 하지만 데이터 복사는 복사 시 추가 시간과 메모리를 소요하게 되며, shared memory의 경우에는 개발 시 고려해야 될 요소들이 많다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;소요되는 자원이 더 적다.
    &lt;ul&gt;
      &lt;li&gt;Thread를 하나 생성하는 것 보다 process를 생성할 때 소요되는 시간과 자원이 훨씬 더 많이 들어간다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;multithreading--단점&quot;&gt;&lt;strong&gt;Multithreading : 단점&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;안정성이 떨어진다.
    &lt;ul&gt;
      &lt;li&gt;만약 여러 thread 들 중 단 하나의 thread라도 문제가 발생할 경우, application이 crash된다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;디버깅 하기 어렵다.
    &lt;ul&gt;
      &lt;li&gt;Multithread 환경에서 디버거를 통해 버그의 원인을 발견하기 어렵다. 따라서 문제가 되는 thread를 발견하기 위해 보통 log를 찾아보며 추적하게 됨으로, 디버깅에 소요되는 시간이 많이 들어가게 된다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;multiprocessing--장점&quot;&gt;&lt;strong&gt;Multiprocessing : 장점&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;안정성이 높다.
    &lt;ul&gt;
      &lt;li&gt;여러 프로세스 실행 중 하나의 프로세스에 문제가 발생할 경우, 해당 프로세스만 종료시키면 된다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;확장성이 크다.
    &lt;ul&gt;
      &lt;li&gt;프로세스는 다른 머신에 할당해서 실행할 수가 있다. 반면에 thread는 단일 프로세스 내에 존재해야 하므로 확장성이 떨어질 수밖에 없다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;multiprocessing--단점&quot;&gt;&lt;strong&gt;Multiprocessing : 단점&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;프로세스 간 커뮤니케션이 복잡하다.
    &lt;ul&gt;
      &lt;li&gt;프로세스 간 데이터를 공유할 때는 별도의 technique (shared memory 또는 inter process communication)을 사용해야 하기 때문이다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;메모리 소요가 크다.
    &lt;ul&gt;
      &lt;li&gt;프로세스 간에는 별도의 독립된 메모리 영역을 갖는다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;</content><author><name>Jaeseo Yu</name></author><category term="Operating system" /><category term="operating system" /><category term="parallel programming" /><summary type="html">Multithreading과 multiprocessing 장단점에 대한 간략한 정리</summary></entry><entry><title type="html">프로그래머스 - 기둥과 보 설치</title><link href="http://localhost:4000/algorithm/2021/09/18/programmers%EA%B8%B0%EB%91%A5%EA%B3%BC%EB%B3%B4%EC%84%A4%EC%B9%98/" rel="alternate" type="text/html" title="프로그래머스 - 기둥과 보 설치" /><published>2021-09-18T00:00:00+09:00</published><updated>2021-09-18T00:00:00+09:00</updated><id>http://localhost:4000/algorithm/2021/09/18/programmers%EA%B8%B0%EB%91%A5%EA%B3%BC%EB%B3%B4%EC%84%A4%EC%B9%98</id><content type="html" xml:base="http://localhost:4000/algorithm/2021/09/18/programmers%EA%B8%B0%EB%91%A5%EA%B3%BC%EB%B3%B4%EC%84%A4%EC%B9%98/">&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;problem&quot;&gt;&lt;strong&gt;Problem&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://programmers.co.kr/learn/courses/30/lessons/60061&quot;&gt;2020 KAKAO BLIND RECRUITMENT 기둥과 보 설치&lt;/a&gt;
&lt;br /&gt;&lt;br /&gt;
문제는 2차원 공간에 구조물 (기둥 or 보)를 설치/삭제 한 후 최종 구조물의 상태를 return 하는 것이다. 구조물의 정보&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(x 좌표, y좌표, 구조물 종류, 설치/삭제)&lt;/code&gt;들을 담은 2차원 배열이 입력되고, 최종 구조물의 상태&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(x 좌표, y 좌표, 구조물 종류)&lt;/code&gt;를 반환하면 된다. 단, 문제에 나온 &lt;strong&gt;특정 조건을 만족해야만 주어진 위치에 기둥과 보를 설치/삭제할 수 있다는 점에 유의&lt;/strong&gt;해야 한다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;solution&quot;&gt;&lt;strong&gt;Solution&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;보와 기둥의 존재 여부를 나타내는 2차원 배열을 각각 만들고, 현재 특정 위치에 구조물이 존재하는 지를 표시한다. 구현할 때, 구조물 설치/삭제 입력에 대해 설치와 삭제 시에 만족해야 하는 특정 조건을 검사하는 것이 까다롭다. 기둥과 보가 존재하기 위해서는 각각의 조건을 만족해야 한다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;기둥
    &lt;ul&gt;
      &lt;li&gt;바닥 위에 존재&lt;/li&gt;
      &lt;li&gt;왼쪽/오른쪽 보의 끝 위에 존재&lt;/li&gt;
      &lt;li&gt;다른 기둥 위에 존재&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;보
    &lt;ul&gt;
      &lt;li&gt;왼쪽/오른쪽 끝 부분이 기둥 위에 존재&lt;/li&gt;
      &lt;li&gt;양쪽 끝 부분이 다른 보와 동시에 연결&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;설치 시에는 위의 조건을 만족하는 지 확인하고, 만족할 경우 설치를 해주면 된다. 반면 삭제할 때는 삭제하려는 기둥, 보의 존재 여부에 영향을 받는 기둥, 보에 대해 위의 유효 조건을 검사해야 한다. 조건을 만족하지 않을 경우 삭제를 할 수 없으므로, 구조물 삭제를 취소해야 한다. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x,y&lt;/code&gt; 좌표에 있는 기둥 또는 보 삭제 시 영향을 받는 구조물은 다음과 같다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;기둥 (x, y)
    &lt;ul&gt;
      &lt;li&gt;바로 위에 존재하는 기둥 (x, y+1)&lt;/li&gt;
      &lt;li&gt;오른쪽 끝이 기둥 위에 존재하는 보 (x-1, y+1)&lt;/li&gt;
      &lt;li&gt;왼쪽 끝이 기둥 위에 존재하는 보 (x, y+1)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;보 (x, y)
    &lt;ul&gt;
      &lt;li&gt;왼쪽 끝 위에 존재하는 기둥 (x, y)&lt;/li&gt;
      &lt;li&gt;오른쪽 끝 위에 존재하는 기둥 (x+1, y)&lt;/li&gt;
      &lt;li&gt;왼쪽 끝에 닿아있는 보 (x-1, y)&lt;/li&gt;
      &lt;li&gt;오른쪽 끝에 닿아있는 보 (x+1, y)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;해당 위치에 있는 특정 기둥과 보만을 검사하면, 모든 구조물을 검사하지 않고 삭제가 가능한지 효과적으로 판단할 수 있다. 주의해야 할 점은, 검사해야 하는 위치에 구조물이 있을 경우에만 유효성 검사를 해야 하는 것이다. 이점을 신경쓰지 못해서 모든 케이스를 통과하는 데 많은 시간이 걸렸다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;code&quot;&gt;&lt;strong&gt;Code&lt;/strong&gt;&lt;/h2&gt;
&lt;div class=&quot;language-c++ highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;#include &amp;lt;vector&amp;gt;
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;namespace&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;101&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;101&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// 기둥 놓을 수 있는지 확인&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;check_0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// 보 놓을 수 있는지 확인&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;check_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])){&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// 기둥 지울 수 있는지 확인&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;check_d_0&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;check_0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;check_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;check_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))){&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// 보 지울 수 있는지 확인 &lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;check_d_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;check_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;check_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;check_0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;check_0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))){&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;construct&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;check_0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)){&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;check_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;deconstruct&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;check_d_0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;check_d_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;solution&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;build_frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;answer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;build_frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
        &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;build_frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
        &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;build_frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
        &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;build_frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
        &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;build_frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;construct&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;deconstruct&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;each_0&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;each_1&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
            
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;each_0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;each_0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;each_0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;answer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;push_back&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;each_0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
            
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]){&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;each_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;each_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;each_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;answer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;push_back&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;each_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;answer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;</content><author><name>Jaeseo Yu</name></author><category term="Algorithm" /><category term="algorithm" /><category term="c++" /><category term="online judge" /><category term="구현/시뮬레이션" /><category term="programmers" /><summary type="html">프로그래머스 구현 문제인 기둥과 보 설치 문제 풀이 및 코드에 대한 정리</summary></entry><entry><title type="html">백준(10816) - 숫자 카드2</title><link href="http://localhost:4000/algorithm/2021/09/16/Baekjoon10816/" rel="alternate" type="text/html" title="백준(10816) - 숫자 카드2" /><published>2021-09-16T00:00:00+09:00</published><updated>2021-09-16T00:00:00+09:00</updated><id>http://localhost:4000/algorithm/2021/09/16/Baekjoon10816</id><content type="html" xml:base="http://localhost:4000/algorithm/2021/09/16/Baekjoon10816/">&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;problem&quot;&gt;&lt;strong&gt;Problem&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Baekjoon-10816.png&quot; alt=&quot;image&quot; width=&quot;100%&quot; height=&quot;100%&quot; class=&quot;align-center&quot; /&gt;
&lt;em&gt;Figure 1. 백준 10816 숫자 카드2 (&lt;a href=&quot;https://www.acmicpc.net/problem/10816&quot;&gt;source&lt;/a&gt;)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;solution&quot;&gt;&lt;strong&gt;Solution&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;문제는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;N&lt;/code&gt;개의 정수 입력이 주어졌을 때, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;M&lt;/code&gt;개의 특정 숫자가 나온 빈도 수를 출력하는 것이다.
숫자의 범위가 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(-10,000,000 &amp;lt;= x &amp;lt;= 10,000,000)&lt;/code&gt; 밖에 안되기 때문에, 가장 간단한 풀이는 x에 최소값을 더해 양수로 변환한 후 배열에 각 숫자가 발생한 빈도를 count하는 것이다. 
다른 방법은 binary search를 응용하는 방법인데, 입력 배열을 오름차순으로 정렬한 다음 아래와 같이 &lt;strong&gt;특정 숫자가 나타나는 범위(lower bound, upper bound)&lt;/strong&gt;를 구해서 푸는 방법이다.
첫번째 방법은 숫자의 범위가 수십억 등 더 큰 단위로 커질 경우 메모리를 많이 사용해야 되며, 대부분의 사람들이 스스로 잘 풀 것이라고 생각한다. 
따라서, 개인적으로 정리도 하는 겸 두번째 방법으로 푸는 방법에 대해 소개하려고 한다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;lower-bound&quot;&gt;&lt;strong&gt;Lower bound&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Lower bound는 특정 값(key)보다 크거나 같은 값의 첫번째 위치를 나타낸다. lower bound 값을 찾기 위해서 binary search와 같이 탐색 공간을 반복적으로 절반씩 줄여 나간다. 이때 주의해야 할 것은 탐색 공간을 줄일 때 right와 left의 값을 어떻게 설정하는 지이다. key 값보다 mid 위치의 값이 크거나 같은 경우 lower bound는 mid의 왼편에 존재하게 되는데, 이때 mid가 lower bound가 될 수 있기 때문에, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;right = mid&lt;/code&gt;로 설정해준다. 반면에 key 값이 mid 위치의 값 보다 큰 경우, mid가 lower bound가 될 가능성이 없기 때문에 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;left = mid + 1&lt;/code&gt;으로 설정한다. 이러한 과정을 lower &amp;lt; right 조건이 만족하는 경우에 한해 반복하고, loop가 끝나면 left 값을 반환하게 된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Baekjoon-10816/Lower-bound1.PNG&quot; alt=&quot;image&quot; width=&quot;85%&quot; height=&quot;70%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Baekjoon-10816/Lower-bound2.PNG&quot; alt=&quot;image&quot; width=&quot;85%&quot; height=&quot;70%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Baekjoon-10816/Lower-bound3.PNG&quot; alt=&quot;image&quot; width=&quot;85%&quot; height=&quot;70%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Baekjoon-10816/Lower-bound4.PNG&quot; alt=&quot;image&quot; width=&quot;85%&quot; height=&quot;70%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Baekjoon-10816/Lower-bound5.PNG&quot; alt=&quot;image&quot; width=&quot;85%&quot; height=&quot;70%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;upper-bound&quot;&gt;&lt;strong&gt;Upper bound&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Upper bound는 특정 값(key)보다 큰 값이 처음으로 나오는 위치를 나타낸다. 만약 key 값이 mid 위치의 값보다 작은 경우 mid가 upper bound가 될 수 있으므로, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;right = mid&lt;/code&gt;로 설정한다. 반면에 key 값이 mid 위치 값보다 크거나 같은 경우, mid가 upper bound가 될 수 없기 때문에 left를 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mid + 1&lt;/code&gt;으로 설정한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Baekjoon-10816/Upper-bound1.PNG&quot; alt=&quot;image&quot; width=&quot;85%&quot; height=&quot;70%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Baekjoon-10816/Upper-bound2.PNG&quot; alt=&quot;image&quot; width=&quot;85%&quot; height=&quot;70%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Baekjoon-10816/Upper-bound3.PNG&quot; alt=&quot;image&quot; width=&quot;85%&quot; height=&quot;70%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/Baekjoon-10816/Upper-bound4.PNG&quot; alt=&quot;image&quot; width=&quot;85%&quot; height=&quot;70%&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;code&quot;&gt;&lt;strong&gt;Code&lt;/strong&gt;&lt;/h2&gt;
&lt;div class=&quot;language-c++ highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;algorithm&amp;gt;
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;namespace&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;500001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;M&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;upperbound&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
	&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	
	&lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;mid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

	&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;lowerbound&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
	&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	
	&lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;mid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

	&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;ios_base&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sync_with_stdio&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tie&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tie&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

	&lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

	&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

	&lt;span class=&quot;n&quot;&gt;sort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

	&lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;M&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

	&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;M&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
		&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
		
		&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lower_idx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lowerbound&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
		&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;upper_idx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;upperbound&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

		&lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;upper_idx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lower_idx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot; &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

	&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;time-complexity&quot;&gt;&lt;strong&gt;Time complexity&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Sorting과 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;2M&lt;/code&gt;번의 binary search 시간을 더하여 $O( (N+M)log{N} )$&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;</content><author><name>Jaeseo Yu</name></author><category term="Algorithm" /><category term="algorithm" /><category term="c++" /><category term="online judge" /><category term="binary search" /><category term="baekjoon" /><summary type="html">Binary search를 응용한 lower bound, upper bound를 찾는 방법에 대해 알아본다.</summary></entry></feed>